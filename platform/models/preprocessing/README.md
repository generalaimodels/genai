# Multimodal Preprocessing Module

High-performance preprocessing infrastructure for text, image, video, audio modalities with Triton kernel acceleration.

## Installation

```bash
# Core dependencies
pip install torch>=2.0 triton>=2.1.0

# Optional dependencies
pip install pillow opencv-python librosa soundfile
```

## Quick Start

```python
from models.preprocessing import MultimodalProcessor, PreprocessingConfig

# Initialize
processor = MultimodalProcessor(device="cuda")

# Process multimodal input
output = processor({
    'role': 'user',
    'content': {
        'input_text': 'Hello world! ðŸ‘‹',
        'input_image': '/path/to/image.jpg',
    }
})

# Access outputs
print(output.input_ids)      # Token IDs
print(output.pixel_values)   # Image tensor
```

## Training Tokenizer

```python
from models.preprocessing.text import train_tokenizer

# From directory
tokenizer = train_tokenizer("./corpus/", vocab_size=32000)

# From HuggingFace dataset
tokenizer = train_tokenizer("wikitext", vocab_size=50000)

# Save
tokenizer.save("./tokenizer/")
```

## Input Schema

```python
{
    'role': str,  # 'user', 'assistant', 'system'
    'content': {
        'input_text': str,           # Unicode, emoji, multilingual
        'input_image': PathOrURL,    # Local path, HTTP/HTTPS
        'input_video': PathOrURL,    # Any video format
        'input_audio': PathOrURL,    # Any audio codec
    }
}
```

## Module Structure

```
preprocessing/
â”œâ”€â”€ config.py          # Configuration dataclasses
â”œâ”€â”€ processor.py       # Unified MultimodalProcessor
â”œâ”€â”€ text/              # Text preprocessing
â”‚   â”œâ”€â”€ tokenizer.py   # BPE tokenizer
â”‚   â”œâ”€â”€ vocabulary.py  # Vocabulary management
â”‚   â”œâ”€â”€ normalizer.py  # Unicode normalization
â”‚   â””â”€â”€ training.py    # Tokenizer training
â”œâ”€â”€ image/             # Image preprocessing
â”‚   â”œâ”€â”€ loader.py      # Multi-format loading
â”‚   â”œâ”€â”€ transforms.py  # Triton transforms
â”‚   â””â”€â”€ processor.py   # Image processor
â”œâ”€â”€ video/             # Video preprocessing
â”‚   â”œâ”€â”€ extractor.py   # Frame extraction
â”‚   â”œâ”€â”€ sampler.py     # Temporal sampling
â”‚   â””â”€â”€ processor.py   # Video processor
â”œâ”€â”€ audio/             # Audio preprocessing
â”‚   â”œâ”€â”€ loader.py      # Multi-codec loading
â”‚   â”œâ”€â”€ spectrogram.py # Mel/MFCC extraction
â”‚   â””â”€â”€ processor.py   # Audio processor
â””â”€â”€ kernels/triton/    # Triton kernels
    â”œâ”€â”€ text_kernels.py
    â”œâ”€â”€ image_kernels.py
    â”œâ”€â”€ audio_kernels.py
    â””â”€â”€ autotune.py
```

## Model Integration

```python
from models import RSSMoDModel, RSSMoDConfig
from models.preprocessing import MultimodalProcessor

# Initialize model
config = RSSMoDConfig.base()
model = RSSMoDModel(config)

# Initialize processor with matching vocab_size
processor = MultimodalProcessor(device="cuda")

# Process input
output = processor({
    'role': 'user',
    'content': {'input_text': 'Example prompt'}
})

# Forward pass
model_output = model(
    input_ids=output.input_ids.unsqueeze(0),
    attention_mask=output.attention_mask.unsqueeze(0),
)
```

## Configuration

```python
from models.preprocessing import PreprocessingConfig

# Default config
config = PreprocessingConfig()

# LLM-optimized
config = PreprocessingConfig.for_llm()

# Vision-optimized
config = PreprocessingConfig.for_vision()

# Multimodal
config = PreprocessingConfig.for_multimodal()
```

## Triton Kernels

| Kernel | Operation | Optimization |
|--------|-----------|--------------|
| `bilinear_resize_kernel` | Image resize | Memory coalescing |
| `normalize_kernel` | Mean/std normalize | Fused operation |
| `mel_filterbank_kernel` | Mel spectrogram | Tiled matmul |
| `fused_tokenize_lookup_kernel` | Embedding lookup | Coalesced access |

## Performance

- **Text**: O(n log v) tokenization
- **Image**: Memory-coalesced resize/normalize
- **Audio**: Triton-accelerated mel filterbank
- **Video**: Efficient frame sampling

## License

MIT
