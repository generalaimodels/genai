{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Algorithms Cheat Sheet (Engineering-Grade)\n",
        "\n",
        "## 0) Graph Theory Introduction\n",
        "\n",
        "### Core objects\n",
        "- **Graph** `G = (V, E)`\n",
        "  - `|V| = n` vertices, `|E| = m` edges\n",
        "- **Directed** vs **Undirected**\n",
        "- **Weighted** vs **Unweighted**\n",
        "- **Simple** graph vs **Multigraph** (parallel edges) vs **Self-loops**\n",
        "- **Path**: sequence of edges; **simple path**: no repeated vertices\n",
        "- **Cycle**: path that starts/ends same vertex\n",
        "- **Connected components** (undirected) / **SCCs** (directed)\n",
        "- **Degree**\n",
        "  - Undirected: `deg(v)`\n",
        "  - Directed: `outdeg(v)`, `indeg(v)`\n",
        "\n",
        "### Representations (pick for asymptotics + cache locality)\n",
        "- **Adjacency List**: best default for sparse graphs (`m ~ O(n)`)\n",
        "  - Iteration over neighbors is `O(deg(v))`\n",
        "  - Total traversal `O(n + m)`\n",
        "- **Edge List**: best for algorithms scanning all edges repeatedly (Bellman-Ford, Kruskal)\n",
        "  - Sequential memory access (good cache locality)\n",
        "- **Adjacency Matrix**: `O(n^2)` memory; only for dense graphs or when `n` is small and constant-bounded\n",
        "- **CSR (Compressed Sparse Row)**: adjacency list with contiguous neighbor arrays\n",
        "  - Best cache locality; avoids pointer chasing in hot paths\n",
        "\n",
        "### Engineering invariants\n",
        "- Vertex IDs normalized to `[0, n-1]`\n",
        "- Input sanity:\n",
        "  - Bounds-check endpoints\n",
        "  - Verify no unbounded reads; cap `n, m` per memory budget\n",
        "  - Use checked arithmetic for `m` sizes, distance sums, `n*n` in matrices\n",
        "- Determinism:\n",
        "  - If output depends on traversal order, sort adjacency or preserve input order consistently\n",
        "\n",
        "---\n",
        "\n",
        "## 1) Problems in Graph Theory (Pattern → Tool)\n",
        "\n",
        "| Problem Type | Typical Constraint | Tool |\n",
        "|---|---:|---|\n",
        "| Reachability / components | unweighted | DFS/BFS |\n",
        "| Shortest path (unweighted) | edges weight = 1 | BFS |\n",
        "| Shortest path (non-negative weights) | `w >= 0` | Dijkstra |\n",
        "| Shortest path (negative edges) | no negative cycles | Bellman-Ford |\n",
        "| All-pairs shortest path | `n <= ~500` typical | Floyd-Warshall |\n",
        "| Topological order | DAG | Kahn / DFS topo |\n",
        "| Longest path | DAG only (general is NP-hard) | DP on topo |\n",
        "| Bridges / articulation points | undirected | Tarjan low-link |\n",
        "| SCCs | directed | Tarjan SCC / Kosaraju |\n",
        "| Eulerian path/circuit | degree constraints | Hierholzer |\n",
        "| MST | undirected, connected | Prim / Kruskal |\n",
        "| Max flow / matching | capacities | Dinic / Edmonds-Karp |\n",
        "| TSP | `n <= ~20..25` for DP | Bitmask DP |\n",
        "\n",
        "---\n",
        "\n",
        "## 2) Depth First Search (DFS)\n",
        "\n",
        "### Use when\n",
        "- Reachability, connected components\n",
        "- Cycle detection (directed/undirected variants)\n",
        "- Topological sort (via postorder)\n",
        "- Bridges / articulation points (as a framework)\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n)` for stack/visited; recursion depth can be `O(n)` (risk stack overflow)\n",
        "\n",
        "### Edge cases\n",
        "- Disconnected graphs: must loop over all vertices\n",
        "- Self-loops / parallel edges (especially for bridge logic)\n",
        "- Deterministic output: neighbor iteration order matters\n",
        "\n",
        "### Pseudocode (iterative to avoid recursion limits)\n",
        "```text\n",
        "// DFS_ITERATIVE(G, start):\n",
        "//   // G adjacency list: for each vertex, contiguous neighbor list preferred (CSR)\n",
        "//   // visited: boolean[n] initialized false\n",
        "//   stack: stack of (v, next_index)\n",
        "//   push (start, 0); visited[start] = true\n",
        "//   while stack not empty:\n",
        "//     (v, i) = top\n",
        "//     if i == degree(v):\n",
        "//       // finished v => postorder hook here if needed\n",
        "//       pop\n",
        "//       continue\n",
        "//     u = adj[v][i]\n",
        "//     top.next_index++\n",
        "//     if not visited[u]:\n",
        "//       visited[u] = true\n",
        "//       push (u, 0)\n",
        "//\n",
        "// Notes:\n",
        "//   - This form gives both preorder (when first discovered) and postorder (when popped).\n",
        "//   - For directed graphs, \"visited\" prevents infinite loops.\n",
        "//   - For cycle detection in directed graphs, add color/state: 0=unseen,1=active,2=done.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Breadth First Search (BFS)\n",
        "\n",
        "### Use when\n",
        "- Unweighted shortest paths (each edge cost = 1)\n",
        "- Level-order traversal, minimum-edge paths\n",
        "- Multi-source shortest paths (push multiple starts)\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n)` queue\n",
        "\n",
        "### Edge cases\n",
        "- Disconnected: BFS from all sources or loop all nodes\n",
        "- Large graphs: use ring-buffer queue for cache locality\n",
        "- Deterministic parents: fixed neighbor order\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// BFS(G, sources):\n",
        "//   dist: int[n], init INF\n",
        "//   parent: int[n], init -1\n",
        "//   queue: FIFO\n",
        "//   for s in sources:\n",
        "//     dist[s] = 0\n",
        "//     push s\n",
        "//   while queue not empty:\n",
        "//     v = pop_front\n",
        "//     for u in adj[v]:\n",
        "//       if dist[u] == INF:\n",
        "//         dist[u] = dist[v] + 1\n",
        "//         parent[u] = v\n",
        "//         push u\n",
        "//\n",
        "// Notes:\n",
        "//   - dist is shortest number of edges from nearest source.\n",
        "//   - parent reconstructs shortest path tree.\n",
        "//   - Use checked_add for dist[v] + 1 if dist can approach integer max (rare but sanitize).\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4) BFS Grid Shortest Path (4/8-neighbor)\n",
        "\n",
        "### Use when\n",
        "- Grid maze shortest path, uniform cost\n",
        "- Obstacles + bounds checks\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(R*C)` (each cell processed once)\n",
        "- Space: `O(R*C)` dist/visited\n",
        "\n",
        "### Edge cases\n",
        "- Multiple starts/targets\n",
        "- Walls, unreachable target\n",
        "- Non-rectangular input (validate row lengths)\n",
        "- Coordinate encoding: avoid overflow in `id = r*C + c` with checked multiplication\n",
        "\n",
        "### Pseudocode (multi-source)\n",
        "```text\n",
        "// GRID_BFS(grid[R][C], starts, is_blocked):\n",
        "//   dist: int[R][C] = INF\n",
        "//   queue\n",
        "//   for (sr, sc) in starts:\n",
        "//     if not is_blocked(sr, sc):\n",
        "//       dist[sr][sc] = 0\n",
        "//       push (sr, sc)\n",
        "//   dirs = [(+1,0),(-1,0),(0,+1),(0,-1)] // or add diagonals\n",
        "//   while queue not empty:\n",
        "//     (r, c) = pop_front\n",
        "//     for (dr, dc) in dirs:\n",
        "//       nr = r + dr; nc = c + dc\n",
        "//       if nr,nc out of bounds: continue\n",
        "//       if is_blocked(nr, nc): continue\n",
        "//       if dist[nr][nc] == INF:\n",
        "//         dist[nr][nc] = dist[r][c] + 1\n",
        "//         push (nr, nc)\n",
        "//\n",
        "// Notes:\n",
        "//   - Use integer bounds checks before indexing.\n",
        "//   - For path reconstruction, store parent cell.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5) Topological Sort (DAG)\n",
        "\n",
        "### Use when\n",
        "- Dependency resolution (prereqs)\n",
        "- Scheduling tasks with constraints\n",
        "- Enables DP on DAG (shortest/longest paths)\n",
        "\n",
        "### Preconditions\n",
        "- Graph must be a DAG for a full topological ordering\n",
        "- If cycle exists: detect and return error variant (not partial silently)\n",
        "\n",
        "### Algorithm A: Kahn’s (in-degree queue)\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n)`\n",
        "- Deterministic: use min-heap / ordered queue if you need lexicographically smallest topo order (cost: `O((n+m) log n)`)\n",
        "\n",
        "```text\n",
        "// TOPO_KAHN(G):\n",
        "//   indeg[n]=0\n",
        "//   for v in 0..n-1:\n",
        "//     for u in adj[v]: indeg[u]++\n",
        "//   queue = all v with indeg[v]==0\n",
        "//   order = empty list\n",
        "//   while queue not empty:\n",
        "//     v = pop_front\n",
        "//     append v to order\n",
        "//     for u in adj[v]:\n",
        "//       indeg[u]--\n",
        "//       if indeg[u]==0: push u\n",
        "//   if len(order) != n:\n",
        "//     // cycle exists => return Error(CYCLE_DETECTED)\n",
        "//   return order\n",
        "//\n",
        "// Notes:\n",
        "//   - indeg decrement must be consistent; parallel edges increment/decrement multiple times (correct).\n",
        "```\n",
        "\n",
        "### Algorithm B: DFS postorder\n",
        "- Also `O(n + m)`\n",
        "- Needs cycle detection with colors\n",
        "\n",
        "---\n",
        "\n",
        "## 6) Shortest / Longest Path on a DAG\n",
        "\n",
        "### Use when\n",
        "- Directed acyclic graph only\n",
        "- Supports negative weights safely (no cycles)\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)` after topo sort\n",
        "- Space: `O(n)`\n",
        "\n",
        "### Edge cases\n",
        "- Unreachable nodes remain INF / -INF\n",
        "- Longest path: initialize to `-INF`, careful with overflow when adding weights\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// DAG_SHORTEST_PATH(G, topo, source):\n",
        "//   dist[n]=INF; dist[source]=0\n",
        "//   for v in topo:\n",
        "//     if dist[v]==INF: continue\n",
        "//     for (u, w) in adj[v]:\n",
        "//       // relax edge v->u\n",
        "//       cand = dist[v] + w  // checked_add to prevent overflow\n",
        "//       if cand < dist[u]: dist[u]=cand\n",
        "//   return dist\n",
        "//\n",
        "// DAG_LONGEST_PATH(G, topo, source):\n",
        "//   dist[n]=-INF; dist[source]=0\n",
        "//   for v in topo:\n",
        "//     if dist[v]==-INF: continue\n",
        "//     for (u, w) in adj[v]:\n",
        "//       cand = dist[v] + w  // checked_add\n",
        "//       if cand > dist[u]: dist[u]=cand\n",
        "//   return dist\n",
        "//\n",
        "// Notes:\n",
        "//   - For longest path, requires DAG; otherwise NP-hard in general graphs.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7) Dijkstra’s Shortest Path\n",
        "\n",
        "### Use when\n",
        "- Weighted graph with **non-negative** edge weights `w >= 0`\n",
        "- Single-source shortest paths\n",
        "\n",
        "### Complexity (binary heap)\n",
        "- Time: `O((n + m) log n)`; practically `O(m log n)`\n",
        "- Space: `O(n + m)`\n",
        "- Comparator costs: heap comparisons are frequent; keep heap keys simple (distance, vertex)\n",
        "\n",
        "### Engineering notes\n",
        "- Prefer adjacency in contiguous memory (CSR)\n",
        "- Use 64-bit distances if weights sum can exceed 32-bit\n",
        "- Avoid decrease-key complexity by pushing duplicates; skip stale heap entries by checking `if d != dist[v] continue`\n",
        "\n",
        "### Edge cases\n",
        "- Multiple edges, self-loops: safe\n",
        "- Zero-weight edges: safe\n",
        "- Negative edge => invalid; return Error(NEGATIVE_EDGE_FOUND)\n",
        "\n",
        "### Pseudocode (source code equivalent, but pseudocode)\n",
        "```text\n",
        "// DIJKSTRA(G, source):\n",
        "//   dist[n]=INF; dist[source]=0\n",
        "//   parent[n]=-1\n",
        "//   heap = min-heap of (dist, vertex)\n",
        "//   push (0, source)\n",
        "//   while heap not empty:\n",
        "//     (d, v) = pop_min\n",
        "//     if d != dist[v]:\n",
        "//       // stale entry due to duplicate pushes\n",
        "//       continue\n",
        "//     for (u, w) in adj[v]:\n",
        "//       if w < 0:\n",
        "//         // must fail fast; Dijkstra assumes non-negative weights\n",
        "//         return Error(NEGATIVE_EDGE_FOUND)\n",
        "//       cand = d + w  // checked_add\n",
        "//       if cand < dist[u]:\n",
        "//         dist[u] = cand\n",
        "//         parent[u] = v\n",
        "//         push (cand, u)\n",
        "//   return (dist, parent)\n",
        "//\n",
        "// Notes:\n",
        "//   - For deterministic parent choice in ties, define tie-break: if cand==dist[u], keep smaller parent id.\n",
        "//   - If you need actual path, reconstruct by following parent[] from target to source.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 8) Bellman-Ford\n",
        "\n",
        "### Use when\n",
        "- Graph may have negative edges\n",
        "- Need to detect negative cycles reachable from source\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n*m)` worst-case (only acceptable when bounded; otherwise too slow)\n",
        "- Space: `O(n)`\n",
        "\n",
        "### Edge cases\n",
        "- Negative cycle not reachable from source: shouldn’t invalidate other distances\n",
        "- For full-cycle marking: after detecting relaxation on nth iteration, propagate “-INF” effect along reachable edges\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// BELLMAN_FORD(edge_list, n, source):\n",
        "//   dist[n]=INF; dist[source]=0\n",
        "//   parent[n]=-1\n",
        "//   // relax edges up to n-1 times\n",
        "//   for i in 1..n-1:\n",
        "//     changed = false\n",
        "//     for each edge (a, b, w):\n",
        "//       if dist[a]==INF: continue\n",
        "//       cand = dist[a] + w  // checked_add\n",
        "//       if cand < dist[b]:\n",
        "//         dist[b]=cand\n",
        "//         parent[b]=a\n",
        "//         changed = true\n",
        "//     if not changed: break\n",
        "//\n",
        "//   // detect negative cycle reachable from source\n",
        "//   neg[n]=false\n",
        "//   for each edge (a, b, w):\n",
        "//     if dist[a]==INF: continue\n",
        "//     cand = dist[a] + w\n",
        "//     if cand < dist[b]:\n",
        "//       neg[b]=true\n",
        "//\n",
        "//   // propagate neg-cycle influence (nodes whose shortest path is undefined => -INF)\n",
        "//   // do n times to saturate reachability\n",
        "//   for i in 1..n:\n",
        "//     for each edge (a, b, w):\n",
        "//       if neg[a]: neg[b]=true\n",
        "//\n",
        "//   return (dist, neg, parent)\n",
        "//\n",
        "// Notes:\n",
        "//   - If neg[v]==true then \"shortest\" is -infinity (arbitrarily low).\n",
        "//   - Must not silently output dist[v] in that case; return an explicit variant.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 9) Floyd–Warshall (All-Pairs Shortest Paths)\n",
        "\n",
        "### Use when\n",
        "- Need all-pairs shortest paths and `n` is small (typical `n <= 400..800` depending on time limits)\n",
        "- Dense graphs or when adjacency matrix is natural\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n^3)` (forbidden for unbounded datasets; only when `n` is explicitly small-bounded)\n",
        "- Space: `O(n^2)`\n",
        "\n",
        "### Edge cases\n",
        "- Negative edges allowed\n",
        "- Negative cycle detection: if `dist[i][i] < 0` after algorithm, negative cycle exists (affects paths through that cycle)\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// FLOYD_WARSHALL(n, dist):\n",
        "//   // dist is n x n matrix:\n",
        "//   // dist[i][j]=0 if i==j, weight(i->j) if edge exists, else INF\n",
        "//   for k in 0..n-1:\n",
        "//     for i in 0..n-1:\n",
        "//       if dist[i][k]==INF: continue\n",
        "//       for j in 0..n-1:\n",
        "//         if dist[k][j]==INF: continue\n",
        "//         cand = dist[i][k] + dist[k][j]  // checked_add\n",
        "//         if cand < dist[i][j]:\n",
        "//           dist[i][j]=cand\n",
        "//   // negative cycle check:\n",
        "//   for i in 0..n-1:\n",
        "//     if dist[i][i] < 0: return Error(NEGATIVE_CYCLE)\n",
        "//   return dist\n",
        "//\n",
        "// Notes:\n",
        "//   - Loop order k-i-j is standard; keep dist rows contiguous for cache locality.\n",
        "//   - Can store next[i][j] to reconstruct paths (update when relax).\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 10) Bridges and Articulation Points (Undirected)\n",
        "\n",
        "### Use when\n",
        "- Identify edges whose removal disconnects graph (**bridges**)\n",
        "- Identify vertices whose removal disconnects graph (**articulation points**)\n",
        "\n",
        "### Preconditions\n",
        "- Undirected graph\n",
        "- Must handle disconnected graphs: run DFS from all unvisited vertices\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n)`\n",
        "\n",
        "### Key idea (Tarjan low-link)\n",
        "- `tin[v]`: discovery time\n",
        "- `low[v]`: lowest `tin` reachable from `v` via:\n",
        "  - zero or more tree edges + at most one back edge\n",
        "\n",
        "### Edge cases\n",
        "- Parallel edges: can invalidate naive “parent edge” skip logic\n",
        "  - Must distinguish edges by unique edge-id, not just parent vertex\n",
        "- Root articulation rule differs\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// BRIDGES_ARTICULATION(G):\n",
        "//   timer=0\n",
        "//   tin[n]=-1\n",
        "//   low[n]=0\n",
        "//   is_art[n]=false\n",
        "//   bridges = empty list\n",
        "//\n",
        "//   DFS(v, parent_edge_id):\n",
        "//     tin[v]=low[v]=timer; timer++\n",
        "//     children=0\n",
        "//     for each (to, edge_id) in adj[v]:\n",
        "//       if edge_id == parent_edge_id: continue\n",
        "//       if tin[to] != -1:\n",
        "//         // back edge\n",
        "//         low[v] = min(low[v], tin[to])\n",
        "//       else:\n",
        "//         children++\n",
        "//         DFS(to, edge_id)\n",
        "//         low[v] = min(low[v], low[to])\n",
        "//         // bridge condition\n",
        "//         if low[to] > tin[v]:\n",
        "//           bridges.add(edge_id)\n",
        "//         // articulation condition (non-root)\n",
        "//         if parent_edge_id != -1 and low[to] >= tin[v]:\n",
        "//           is_art[v]=true\n",
        "//     // root articulation\n",
        "//     if parent_edge_id == -1 and children >= 2:\n",
        "//       is_art[v]=true\n",
        "//\n",
        "//   for v in 0..n-1:\n",
        "//     if tin[v]==-1: DFS(v, -1)\n",
        "//   return (bridges, is_art)\n",
        "//\n",
        "// Notes:\n",
        "//   - Edge-id is mandatory to handle multiedges correctly.\n",
        "//   - For self-loops: treated as back edge to itself; does not create bridges.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 11) Tarjan’s Strongly Connected Components (SCC) (Directed)\n",
        "\n",
        "### Use when\n",
        "- Compress directed graph into SCC DAG\n",
        "- Solve reachability/cycle structure questions\n",
        "- 2-SAT, dominance of cycles, etc.\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n)`\n",
        "\n",
        "### Edge cases\n",
        "- Disconnected directed graph: run from all nodes\n",
        "- Deterministic SCC numbering depends on adjacency order\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// TARJAN_SCC(G):\n",
        "//   timer=0\n",
        "//   disc[n]=-1      // discovery index\n",
        "//   low[n]=0\n",
        "//   on_stack[n]=false\n",
        "//   st = stack\n",
        "//   scc_id[n]=-1\n",
        "//   scc_count=0\n",
        "//\n",
        "//   DFS(v):\n",
        "//     disc[v]=low[v]=timer; timer++\n",
        "//     st.push(v); on_stack[v]=true\n",
        "//     for to in adj[v]:\n",
        "//       if disc[to]==-1:\n",
        "//         DFS(to)\n",
        "//         low[v]=min(low[v], low[to])\n",
        "//       else if on_stack[to]:\n",
        "//         low[v]=min(low[v], disc[to])\n",
        "//     // root of SCC\n",
        "//     if low[v]==disc[v]:\n",
        "//       while true:\n",
        "//         x=st.pop()\n",
        "//         on_stack[x]=false\n",
        "//         scc_id[x]=scc_count\n",
        "//         if x==v: break\n",
        "//       scc_count++\n",
        "//\n",
        "//   for v in 0..n-1:\n",
        "//     if disc[v]==-1: DFS(v)\n",
        "//   return (scc_id, scc_count)\n",
        "//\n",
        "// Notes:\n",
        "//   - disc is strictly increasing; low tracks reachable earliest active node.\n",
        "//   - Output SCC graph can be built by scanning edges and connecting scc_id[u] -> scc_id[v] when different.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 12) Travelling Salesman Problem (TSP) via DP (Bitmask)\n",
        "\n",
        "### Use when\n",
        "- `n` small (typical `n <= 20..22` practical)\n",
        "- Need exact optimal Hamiltonian cycle/path\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n^2 * 2^n)`\n",
        "- Space: `O(n * 2^n)`\n",
        "- This is exponential; only valid for explicitly small-bounded `n`\n",
        "\n",
        "### Variants\n",
        "- **Cycle**: return to start\n",
        "- **Path**: end anywhere or fixed end\n",
        "\n",
        "### Edge cases\n",
        "- Disconnected graph: transitions may be INF\n",
        "- Overflow: distances can exceed 32-bit\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// TSP_DP(dist, start):\n",
        "//   // dist is n x n cost matrix; dist[i][j]=INF if no edge\n",
        "//   // dp[mask][v] = min cost to start at 'start', visit exactly 'mask', and end at v\n",
        "//   dp = map or array sized (2^n) x n initialized INF\n",
        "//   dp[1<<start][start]=0\n",
        "//   for mask in 0..(2^n - 1):\n",
        "//     if (mask & (1<<start))==0: continue\n",
        "//     for v in 0..n-1:\n",
        "//       if dp[mask][v]==INF: continue\n",
        "//       if (mask & (1<<v))==0: continue\n",
        "//       for u in 0..n-1:\n",
        "//         if (mask & (1<<u))!=0: continue\n",
        "//         cand = dp[mask][v] + dist[v][u]  // checked_add\n",
        "//         dp[mask | (1<<u)][u] = min(dp[mask | (1<<u)][u], cand)\n",
        "//   full = (1<<n)-1\n",
        "//   ans = INF\n",
        "//   for v in 0..n-1:\n",
        "//     cand = dp[full][v] + dist[v][start] // for cycle; omit for path variant\n",
        "//     ans = min(ans, cand)\n",
        "//   return ans\n",
        "//\n",
        "// Notes:\n",
        "//   - Store parent pointers if reconstruction required.\n",
        "//   - Use iterative loops to maximize locality; dp as flat array [mask*n + v].\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 13) Existence of Eulerian Paths and Circuits\n",
        "\n",
        "### Eulerian trail facts\n",
        "- **Undirected**\n",
        "  - Eulerian **circuit** exists iff:\n",
        "    - every vertex with nonzero degree is in the same connected component\n",
        "    - all vertices have even degree\n",
        "  - Eulerian **path** (not circuit) exists iff:\n",
        "    - exactly 0 or 2 vertices have odd degree\n",
        "    - all nonzero-degree vertices connected\n",
        "- **Directed**\n",
        "  - Eulerian **circuit** exists iff:\n",
        "    - for all v: `indeg(v) == outdeg(v)`\n",
        "    - all vertices with nonzero degree are in one SCC of the underlying graph (usually check connectivity in “edge-present” subgraph)\n",
        "  - Eulerian **path** exists iff:\n",
        "    - one start with `outdeg = indeg + 1`\n",
        "    - one end with `indeg = outdeg + 1`\n",
        "    - all others `indeg == outdeg`\n",
        "    - connectivity condition holds\n",
        "\n",
        "### Edge cases\n",
        "- Graph with zero edges: trivially Eulerian (path/circuit depends on definition; treat as circuit of length 0)\n",
        "- Multiple edges and self-loops are allowed; algorithm must track edge usage by edge-id\n",
        "\n",
        "---\n",
        "\n",
        "## 14) Eulerian Path Algorithm (Hierholzer)\n",
        "\n",
        "### Use when\n",
        "- Need actual Eulerian path/circuit (uses each edge exactly once)\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n + m)`\n",
        "- Space: `O(n + m)`\n",
        "\n",
        "### Pseudocode (works with edge-ids; directed/undirected)\n",
        "```text\n",
        "// HIERHOLZER(G, start):\n",
        "//   // G adjacency: list of (to, edge_id)\n",
        "//   // used[edge_id]=false\n",
        "//   // it[v] = current index into adjacency list (for O(m) total scanning)\n",
        "//   it[n]=0\n",
        "//   st = stack of vertices\n",
        "//   path = empty list\n",
        "//   st.push(start)\n",
        "//   while st not empty:\n",
        "//     v = st.top()\n",
        "//     // advance iterator to next unused edge\n",
        "//     while it[v] < degree(v) and used[ adj[v][it[v]].edge_id ]:\n",
        "//       it[v]++\n",
        "//     if it[v] == degree(v):\n",
        "//       // dead end => add to output\n",
        "//       path.append(v)\n",
        "//       st.pop()\n",
        "//     else:\n",
        "//       (to, id) = adj[v][it[v]]\n",
        "//       used[id]=true\n",
        "//       st.push(to)\n",
        "//   // path is in reverse\n",
        "//   reverse(path)\n",
        "//   // validate: path length should be m+1 (for connected edge-set)\n",
        "//   if len(path) != m+1: return Error(NOT_EULERIAN_OR_DISCONNECTED)\n",
        "//   return path\n",
        "//\n",
        "// Notes:\n",
        "//   - For undirected graphs, each undirected edge must appear twice in adjacency but share one edge_id.\n",
        "//   - Connectivity requirement should be validated beforehand to avoid partial outputs.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 15) Prim’s Minimum Spanning Tree (MST)\n",
        "\n",
        "### Use when\n",
        "- Undirected weighted graph\n",
        "- Want MST (or MSF if disconnected)\n",
        "- Prim is strong for dense graphs with adjacency matrix; also fine with heap for sparse\n",
        "\n",
        "### Complexity (binary heap)\n",
        "- Time: `O(m log n)`\n",
        "- Space: `O(n + m)`\n",
        "\n",
        "### Edge cases\n",
        "- Disconnected graph: returns minimum spanning forest (or explicit error if MST requires connected)\n",
        "- Negative weights: allowed (MST still well-defined)\n",
        "- Parallel edges: ok, picks cheapest\n",
        "\n",
        "### Pseudocode (lazy Prim)\n",
        "```text\n",
        "// PRIM_LAZY(G):\n",
        "//   in_mst[n]=false\n",
        "//   mst_edges = empty\n",
        "//   total=0\n",
        "//   for each component root s:\n",
        "//     if in_mst[s]: continue\n",
        "//     heap = min-heap of (w, from, to)\n",
        "//     push all edges from s\n",
        "//     in_mst[s]=true\n",
        "//     while heap not empty:\n",
        "//       (w, a, b) = pop_min\n",
        "//       if in_mst[b]: continue\n",
        "//       // add edge to MST\n",
        "//       in_mst[b]=true\n",
        "//       mst_edges.add(a,b,w)\n",
        "//       total += w\n",
        "//       for (to, w2) in adj[b]:\n",
        "//         if not in_mst[to]: push(w2, b, to)\n",
        "//   return (mst_edges, total)\n",
        "//\n",
        "// Notes:\n",
        "//   - Lazy Prim pushes many edges; eager Prim is tighter and often faster.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 16) Eager Prim’s MST\n",
        "\n",
        "### Use when\n",
        "- Need fewer heap operations than lazy Prim\n",
        "- Preferable for large sparse graphs\n",
        "\n",
        "### Complexity\n",
        "- With binary heap + decrease-key via “push duplicates and skip stale”: `O(m log n)`\n",
        "- True decrease-key heap: `O(m log n)` but with lower constants\n",
        "\n",
        "### Pseudocode (eager with best-known edge per vertex)\n",
        "```text\n",
        "// PRIM_EAGER(G):\n",
        "//   key[n]=INF            // best edge weight to connect vertex into MST\n",
        "//   parent[n]=-1\n",
        "//   in_mst[n]=false\n",
        "//   heap = min-heap of (key, v)\n",
        "//\n",
        "//   for each component root s:\n",
        "//     if in_mst[s]: continue\n",
        "//     key[s]=0\n",
        "//     push(0, s)\n",
        "//     while heap not empty:\n",
        "//       (k, v) = pop_min\n",
        "//       if in_mst[v]: continue\n",
        "//       if k != key[v]: continue   // stale\n",
        "//       in_mst[v]=true\n",
        "//       for (to, w) in adj[v]:\n",
        "//         if in_mst[to]: continue\n",
        "//         if w < key[to]:\n",
        "//           key[to]=w\n",
        "//           parent[to]=v\n",
        "//           push(key[to], to)\n",
        "//\n",
        "//   // edges are (parent[v], v) where parent[v]!=-1\n",
        "//   return (parent, key)\n",
        "//\n",
        "// Notes:\n",
        "//   - key[] + parent[] defines the MST forest.\n",
        "//   - Determinism in ties: if w==key[to], pick smaller parent id.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 17) Max Flow (Ford–Fulkerson Framework)\n",
        "\n",
        "### Use when\n",
        "- Compute max `s->t` flow in capacitated directed graph\n",
        "- Also solves matching and many allocation problems via reductions\n",
        "\n",
        "### Core residual graph concept\n",
        "- Each edge has:\n",
        "  - capacity `cap`\n",
        "  - flow `f`\n",
        "  - residual forward capacity: `cap - f`\n",
        "  - residual backward capacity: `f`\n",
        "- Augment along an `s->t` path in residual graph\n",
        "\n",
        "### Pitfalls\n",
        "- Naive DFS augmenting can be exponential if capacities are irrational or path choices are bad\n",
        "- For integer capacities, terminates, but can still be too slow\n",
        "- Prefer Edmonds–Karp, Dinic, or Capacity Scaling in practice\n",
        "\n",
        "---\n",
        "\n",
        "## 18) Unweighted Bipartite Matching via Flow\n",
        "\n",
        "### Use when\n",
        "- Bipartite graph `L`–`R`, unweighted, maximize matches\n",
        "\n",
        "### Reduction\n",
        "- Source `S` to each `u in L` capacity 1\n",
        "- Each original edge `u->v` capacity 1\n",
        "- Each `v in R` to sink `T` capacity 1\n",
        "- Max flow equals max matching\n",
        "\n",
        "### Complexity choice\n",
        "- For unweighted bipartite matching, **Hopcroft–Karp** is specialized (`O(m sqrt n)`), but if constrained to “network flow section,” Dinic on unit networks is very fast.\n",
        "\n",
        "### Edge cases\n",
        "- Isolated vertices\n",
        "- Multiple edges (safe; redundant)\n",
        "\n",
        "---\n",
        "\n",
        "## 19) “Mice and Owls” via Network Flow (Canonical Reduction)\n",
        "\n",
        "### Typical structure (general pattern)\n",
        "- Entities that must be assigned to resources with constraints:\n",
        "  - mice → holes (capacity per hole)\n",
        "  - mouse can go to certain holes if reachable within time/distance\n",
        "- Build bipartite graph (mouse → hole) edges when feasible\n",
        "- Then run max flow / matching\n",
        "\n",
        "### Engineering checklist\n",
        "- Precompute feasibility edges efficiently:\n",
        "  - If geometric distance: compute squared distances to avoid floating error; compare against squared threshold\n",
        "  - If grid distance with obstacles: run BFS from holes (multi-source) or from each mouse depending on counts (choose asymptotically)\n",
        "\n",
        "---\n",
        "\n",
        "## 20) “Elementary Math” via Network Flow (Canonical Reduction)\n",
        "\n",
        "### Typical structure (general pattern)\n",
        "- Assign each pair `(a,b)` one operation result among `{a+b, a-b, a*b}` such that all results are distinct.\n",
        "- Build bipartite:\n",
        "  - Left: each pair index `i`\n",
        "  - Right: each possible result value node\n",
        "  - Edge if pair i can produce that result via some operation\n",
        "- Find perfect matching (flow) to assign unique results.\n",
        "\n",
        "### Edge cases\n",
        "- Duplicate results across different operations/pairs\n",
        "- Large result values: compress coordinate values to `[0..K-1]` to keep memory bounded\n",
        "\n",
        "---\n",
        "\n",
        "## 21) Edmonds–Karp (Max Flow)\n",
        "\n",
        "### Use when\n",
        "- Need a simple, deterministic max-flow\n",
        "- Graph sizes moderate\n",
        "\n",
        "### Algorithm\n",
        "- Ford–Fulkerson where augmenting path is found by BFS in residual graph (shortest in edges)\n",
        "\n",
        "### Complexity\n",
        "- Time: `O(n * m^2)` worst-case\n",
        "- Space: `O(n + m)`\n",
        "- Too slow for large dense graphs; use Dinic\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// EDMONDS_KARP(N, edges, s, t):\n",
        "//   // adjacency stores indices of residual edges; each edge has (to, rev, cap)\n",
        "//   flow=0\n",
        "//   while true:\n",
        "//     parent_v[N]=-1\n",
        "//     parent_e[N]=-1\n",
        "//     queue\n",
        "//     parent_v[s]=s\n",
        "//     push s\n",
        "//     while queue not empty and parent_v[t]==-1:\n",
        "//       v=pop_front\n",
        "//       for ei in adj[v]:\n",
        "//         e = edges[ei]\n",
        "//         if parent_v[e.to]==-1 and e.cap > 0:\n",
        "//           parent_v[e.to]=v\n",
        "//           parent_e[e.to]=ei\n",
        "//           push e.to\n",
        "//     if parent_v[t]==-1: break // no augmenting path\n",
        "//     // find bottleneck\n",
        "//     add=INF\n",
        "//     v=t\n",
        "//     while v!=s:\n",
        "//       ei=parent_e[v]\n",
        "//       add=min(add, edges[ei].cap)\n",
        "//       v=parent_v[v]\n",
        "//     // augment\n",
        "//     v=t\n",
        "//     while v!=s:\n",
        "//       ei=parent_e[v]\n",
        "//       edges[ei].cap -= add\n",
        "//       edges[edges[ei].rev].cap += add\n",
        "//       v=parent_v[v]\n",
        "//     flow += add\n",
        "//   return flow\n",
        "//\n",
        "// Notes:\n",
        "//   - Use 64-bit capacities if totals can exceed 32-bit.\n",
        "//   - Graph must be built with explicit reverse edges for O(1) residual updates.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 22) Capacity Scaling (Max Flow)\n",
        "\n",
        "### Use when\n",
        "- Large integer capacities; want fewer augmentations than plain FF/EK\n",
        "- Works well when capacities vary widely\n",
        "\n",
        "### Idea\n",
        "- Maintain threshold `Δ` (power of 2)\n",
        "- Only consider residual edges with capacity ≥ `Δ`\n",
        "- Find augmenting paths under this restriction; then halve `Δ`\n",
        "\n",
        "### Complexity (typical statement)\n",
        "- `O(m^2 log U)` in some analyses for DFS-style; depends on implementation details\n",
        "- In practice: often speeds up Ford–Fulkerson substantially on large capacities\n",
        "\n",
        "### Pseudocode (high level)\n",
        "```text\n",
        "// CAPACITY_SCALING_MAXFLOW(G, s, t):\n",
        "//   U = max capacity in network\n",
        "//   Delta = highest power of 2 <= U\n",
        "//   flow=0\n",
        "//   while Delta >= 1:\n",
        "//     while true:\n",
        "//       // find any s->t path using only edges with cap >= Delta\n",
        "//       path = DFS_or_BFS_with_threshold(Delta)\n",
        "//       if no path: break\n",
        "//       add = bottleneck_on_path\n",
        "//       augment(add)\n",
        "//       flow += add\n",
        "//     Delta /= 2\n",
        "//   return flow\n",
        "//\n",
        "// Notes:\n",
        "//   - Determinism: fix adjacency scan order.\n",
        "//   - Still inferior to Dinic on many benchmarks, but a solid intermediate.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 23) Dinic’s Algorithm (Max Flow)\n",
        "\n",
        "### Use when\n",
        "- High-performance max flow in general graphs\n",
        "- Standard competitive + production choice for integral capacities\n",
        "\n",
        "### Core components\n",
        "1. **Level graph** via BFS from `s` using residual edges with cap > 0\n",
        "2. **Blocking flow** via DFS sending flow along level-respecting edges\n",
        "3. Use `ptr[v]` current-edge pointer to ensure `O(m)` per BFS phase in practice\n",
        "\n",
        "### Complexity\n",
        "- General: `O(m n^2)` worst-case (rarely tight in practice)\n",
        "- Unit networks / bipartite matching: significantly faster (often near `O(m sqrt n)` behavior in practice with structure)\n",
        "- Space: `O(n + m)`\n",
        "\n",
        "### Engineering notes\n",
        "- Use contiguous arrays for edges: `(to, cap, next/rev)` to minimize pointer chasing\n",
        "- Avoid recursion depth issues in DFS (can be iterative, but recursive often acceptable with bounded stack; sanitize)\n",
        "- Explicitly return error on overflow in `cap` arithmetic\n",
        "\n",
        "### Pseudocode\n",
        "```text\n",
        "// DINIC(N, s, t):\n",
        "//   flow=0\n",
        "//   while BFS_LEVELS():\n",
        "//     ptr[N]=0\n",
        "//     while true:\n",
        "//       pushed = DFS_BLOCKING(s, INF)\n",
        "//       if pushed==0: break\n",
        "//       flow += pushed\n",
        "//   return flow\n",
        "//\n",
        "// BFS_LEVELS():\n",
        "//   level[N]=-1\n",
        "//   queue\n",
        "//   level[s]=0; push s\n",
        "//   while queue not empty:\n",
        "//     v=pop_front\n",
        "//     for ei in adj[v]:\n",
        "//       e=edges[ei]\n",
        "//       if e.cap>0 and level[e.to]==-1:\n",
        "//         level[e.to]=level[v]+1\n",
        "//         push e.to\n",
        "//   return level[t]!=-1\n",
        "//\n",
        "// DFS_BLOCKING(v, pushed):\n",
        "//   if pushed==0: return 0\n",
        "//   if v==t: return pushed\n",
        "//   for i from ptr[v] to degree(v)-1:\n",
        "//     ptr[v]=i\n",
        "//     ei=adj[v][i]\n",
        "//     e=edges[ei]\n",
        "//     if e.cap>0 and level[e.to]==level[v]+1:\n",
        "//       tr = DFS_BLOCKING(e.to, min(pushed, e.cap))\n",
        "//       if tr>0:\n",
        "//         e.cap -= tr\n",
        "//         edges[e.rev].cap += tr\n",
        "//         return tr\n",
        "//   return 0\n",
        "//\n",
        "// Notes:\n",
        "//   - ptr[v] prevents re-scanning dead edges, critical for performance.\n",
        "//   - For determinism: adjacency order fixed; stable iteration yields stable flows.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 24) Practical Selection Guide (What to Use When)\n",
        "\n",
        "- **Reachability / components**\n",
        "  - Use: BFS/DFS\n",
        "  - If recursion risk: iterative DFS\n",
        "- **Unweighted shortest path**\n",
        "  - Use: BFS (multi-source supported)\n",
        "- **Weighted shortest path**\n",
        "  - `w >= 0`: Dijkstra\n",
        "  - Negative edges: Bellman-Ford (and detect cycles)\n",
        "  - DAG: topo + DP (fastest, supports negative)\n",
        "- **All-pairs shortest path**\n",
        "  - Small `n`: Floyd–Warshall\n",
        "  - Larger sparse: run Dijkstra from each node if `w>=0` (`O(n*m log n)`)\n",
        "- **DAG ordering / scheduling**\n",
        "  - Kahn topo (cycle detection built-in)\n",
        "- **Cycle structure**\n",
        "  - Directed SCC: Tarjan SCC\n",
        "  - Undirected bridges/AP: low-link\n",
        "- **MST**\n",
        "  - Sparse: Prim eager or Kruskal (not listed, but valid alternative)\n",
        "  - Dense: Prim with matrix `O(n^2)` only if `n` is small-bounded\n",
        "- **Max flow / matching**\n",
        "  - Default: Dinic\n",
        "  - Educational/simple: Edmonds–Karp (but beware `O(n*m^2)`)\n",
        "\n",
        "---\n",
        "\n",
        "## 25) Cross-Cutting Edge Cases & Correctness Invariants\n",
        "\n",
        "- **Disconnected graphs**\n",
        "  - Many algorithms require looping all nodes (DFS/BFS/bridges/SCC/topo for full coverage)\n",
        "- **Parallel edges**\n",
        "  - Bridges/articulation/Euler need **edge-id** to avoid “parent vertex” ambiguity\n",
        "- **Self-loops**\n",
        "  - Shortest paths: harmless\n",
        "  - Bridges: never a bridge\n",
        "  - Euler: contributes 2 to degree in undirected? (implementation-defined; treat carefully)\n",
        "- **Overflow**\n",
        "  - Distances: use 64-bit; checked add when summing weights\n",
        "  - Matrices: `n*n` memory sizing must be checked\n",
        "- **Negative cycles**\n",
        "  - Only Bellman-Ford / Floyd–Warshall can detect reliably; Dijkstra must reject negative edges\n",
        "- **Deterministic behavior**\n",
        "  - Fix adjacency order; define tie-breaks in relaxations; avoid hash-map iteration order for outputs\n",
        "- **Complexity discipline**\n",
        "  - Avoid `O(n^2)` unless `n` explicitly bounded (same for `O(n^3)` Floyd, `O(2^n)` TSP)\n",
        "  - Prefer contiguous memory (CSR / flat edge arrays) for cache locality\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2Mj59oyxu1rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N6drfvDV2ODo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rKIzdI-m2Nzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Theory - Complete Pseudocode Reference\n",
        "\n",
        "## Table of Contents\n",
        "1. [Graph Theory Introduction](#1-graph-theory-introduction)\n",
        "2. [Depth First Search (DFS)](#2-depth-first-search-dfs)\n",
        "3. [Breadth First Search (BFS)](#3-breadth-first-search-bfs)\n",
        "4. [BFS Grid Shortest Path](#4-bfs-grid-shortest-path)\n",
        "5. [Topological Sort](#5-topological-sort)\n",
        "6. [Shortest/Longest Path on DAG](#6-shortestlongest-path-on-dag)\n",
        "7. [Dijkstra's Algorithm](#7-dijkstras-algorithm)\n",
        "8. [Bellman-Ford Algorithm](#8-bellman-ford-algorithm)\n",
        "9. [Floyd-Warshall Algorithm](#9-floyd-warshall-algorithm)\n",
        "10. [Bridges and Articulation Points](#10-bridges-and-articulation-points)\n",
        "11. [Tarjan's SCC Algorithm](#11-tarjans-scc-algorithm)\n",
        "12. [Travelling Salesman Problem](#12-travelling-salesman-problem-dp)\n",
        "13. [Eulerian Paths and Circuits](#13-eulerian-paths-and-circuits)\n",
        "14. [Prim's MST Algorithm](#14-prims-mst-algorithm)\n",
        "15. [Max Flow Ford-Fulkerson](#15-max-flow-ford-fulkerson)\n",
        "16. [Edmonds-Karp Algorithm](#16-edmonds-karp-algorithm)\n",
        "17. [Capacity Scaling](#17-capacity-scaling)\n",
        "18. [Dinic's Algorithm](#18-dinics-algorithm)\n",
        "19. [Bipartite Matching](#19-bipartite-matching)\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Graph Theory Introduction\n",
        "\n",
        "### Graph Representation Types\n",
        "\n",
        "```\n",
        "// ADJACENCY MATRIX - O(V²) space\n",
        "// Best for: Dense graphs, frequent edge existence queries\n",
        "// Edge lookup: O(1), Space: O(V²)\n",
        "STRUCTURE AdjacencyMatrix:\n",
        "    matrix[V][V] ← 2D array of size V×V\n",
        "    \n",
        "    FUNCTION addEdge(u, v, weight):\n",
        "        matrix[u][v] ← weight\n",
        "        IF undirected THEN matrix[v][u] ← weight\n",
        "    \n",
        "    FUNCTION hasEdge(u, v):\n",
        "        RETURN matrix[u][v] ≠ 0\n",
        "\n",
        "// ADJACENCY LIST - O(V + E) space\n",
        "// Best for: Sparse graphs, iteration over neighbors\n",
        "// Edge lookup: O(degree), Space: O(V + E)\n",
        "STRUCTURE AdjacencyList:\n",
        "    adj[V] ← array of V empty lists\n",
        "    \n",
        "    FUNCTION addEdge(u, v, weight):\n",
        "        adj[u].append((v, weight))\n",
        "        IF undirected THEN adj[v].append((u, weight))\n",
        "    \n",
        "    FUNCTION getNeighbors(u):\n",
        "        RETURN adj[u]\n",
        "\n",
        "// EDGE LIST - O(E) space\n",
        "// Best for: Bellman-Ford, Kruskal's MST\n",
        "STRUCTURE EdgeList:\n",
        "    edges ← empty list of (u, v, weight)\n",
        "    \n",
        "    FUNCTION addEdge(u, v, weight):\n",
        "        edges.append((u, v, weight))\n",
        "```\n",
        "\n",
        "### Graph Types Classification\n",
        "\n",
        "```\n",
        "// DIRECTED vs UNDIRECTED\n",
        "// Directed: edges have direction (u → v)\n",
        "// Undirected: edges are bidirectional (u ↔ v)\n",
        "\n",
        "// WEIGHTED vs UNWEIGHTED  \n",
        "// Weighted: edges have associated costs/distances\n",
        "// Unweighted: all edges have equal cost (typically 1)\n",
        "\n",
        "// CYCLIC vs ACYCLIC\n",
        "// Cyclic: contains at least one cycle\n",
        "// Acyclic: no cycles exist (DAG for directed)\n",
        "\n",
        "// CONNECTED vs DISCONNECTED\n",
        "// Connected: path exists between any two vertices\n",
        "// Disconnected: some vertices unreachable from others\n",
        "\n",
        "// DENSE vs SPARSE\n",
        "// Dense: E ≈ V², use adjacency matrix\n",
        "// Sparse: E << V², use adjacency list\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Depth First Search (DFS)\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// DFS RECURSIVE VERSION\n",
        "// Use case: Path finding, cycle detection, topological sort\n",
        "// Edge case: Handle disconnected components\n",
        "FUNCTION DFS_Recursive(graph, start):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    result ← empty list\n",
        "    \n",
        "    FUNCTION explore(node):\n",
        "        IF visited[node] THEN RETURN\n",
        "        visited[node] ← TRUE\n",
        "        result.append(node)\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            IF NOT visited[neighbor]:\n",
        "                explore(neighbor)\n",
        "    \n",
        "    explore(start)\n",
        "    RETURN result\n",
        "\n",
        "// DFS ITERATIVE VERSION (Stack-based)\n",
        "// Advantage: No stack overflow for deep graphs\n",
        "FUNCTION DFS_Iterative(graph, start):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    stack ← empty stack\n",
        "    result ← empty list\n",
        "    \n",
        "    stack.push(start)\n",
        "    \n",
        "    WHILE stack is NOT empty:\n",
        "        node ← stack.pop()\n",
        "        \n",
        "        IF visited[node] THEN CONTINUE\n",
        "        visited[node] ← TRUE\n",
        "        result.append(node)\n",
        "        \n",
        "        // Push neighbors in reverse for correct order\n",
        "        FOR each neighbor IN reverse(graph.getNeighbors(node)):\n",
        "            IF NOT visited[neighbor]:\n",
        "                stack.push(neighbor)\n",
        "    \n",
        "    RETURN result\n",
        "\n",
        "// DFS FOR ALL COMPONENTS\n",
        "// Handles disconnected graphs\n",
        "FUNCTION DFS_AllComponents(graph):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    components ← empty list\n",
        "    \n",
        "    FOR each vertex v IN graph:\n",
        "        IF NOT visited[v]:\n",
        "            component ← DFS_Recursive(graph, v)\n",
        "            components.append(component)\n",
        "    \n",
        "    RETURN components\n",
        "```\n",
        "\n",
        "### DFS Applications\n",
        "\n",
        "```\n",
        "// CYCLE DETECTION (Directed Graph)\n",
        "FUNCTION hasCycle_Directed(graph):\n",
        "    WHITE, GRAY, BLACK ← 0, 1, 2\n",
        "    color ← array of size V, initialized to WHITE\n",
        "    \n",
        "    FUNCTION dfs(node):\n",
        "        color[node] ← GRAY\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            IF color[neighbor] = GRAY:\n",
        "                RETURN TRUE  // Back edge found = cycle\n",
        "            IF color[neighbor] = WHITE AND dfs(neighbor):\n",
        "                RETURN TRUE\n",
        "        \n",
        "        color[node] ← BLACK\n",
        "        RETURN FALSE\n",
        "    \n",
        "    FOR each vertex v IN graph:\n",
        "        IF color[v] = WHITE AND dfs(v):\n",
        "            RETURN TRUE\n",
        "    RETURN FALSE\n",
        "\n",
        "// CYCLE DETECTION (Undirected Graph)\n",
        "FUNCTION hasCycle_Undirected(graph):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    \n",
        "    FUNCTION dfs(node, parent):\n",
        "        visited[node] ← TRUE\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            IF NOT visited[neighbor]:\n",
        "                IF dfs(neighbor, node):\n",
        "                    RETURN TRUE\n",
        "            ELSE IF neighbor ≠ parent:\n",
        "                RETURN TRUE  // Back edge to non-parent = cycle\n",
        "        \n",
        "        RETURN FALSE\n",
        "    \n",
        "    FOR each vertex v IN graph:\n",
        "        IF NOT visited[v] AND dfs(v, -1):\n",
        "            RETURN TRUE\n",
        "    RETURN FALSE\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Breadth First Search (BFS)\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// BFS STANDARD IMPLEMENTATION\n",
        "// Use case: Shortest path (unweighted), level-order traversal\n",
        "// Guarantees: Visits nodes in order of distance from source\n",
        "FUNCTION BFS(graph, start):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    distance ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    queue ← empty queue\n",
        "    \n",
        "    visited[start] ← TRUE\n",
        "    distance[start] ← 0\n",
        "    queue.enqueue(start)\n",
        "    \n",
        "    WHILE queue is NOT empty:\n",
        "        node ← queue.dequeue()\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            IF NOT visited[neighbor]:\n",
        "                visited[neighbor] ← TRUE\n",
        "                distance[neighbor] ← distance[node] + 1\n",
        "                parent[neighbor] ← node\n",
        "                queue.enqueue(neighbor)\n",
        "    \n",
        "    RETURN distance, parent\n",
        "\n",
        "// PATH RECONSTRUCTION\n",
        "FUNCTION reconstructPath(parent, start, end):\n",
        "    IF parent[end] = -1 AND end ≠ start:\n",
        "        RETURN NULL  // No path exists\n",
        "    \n",
        "    path ← empty list\n",
        "    current ← end\n",
        "    \n",
        "    WHILE current ≠ -1:\n",
        "        path.prepend(current)\n",
        "        current ← parent[current]\n",
        "    \n",
        "    RETURN path\n",
        "\n",
        "// BFS SHORTEST PATH (Unweighted)\n",
        "FUNCTION shortestPath_BFS(graph, start, end):\n",
        "    distance, parent ← BFS(graph, start)\n",
        "    \n",
        "    IF distance[end] = INFINITY:\n",
        "        RETURN NULL, INFINITY\n",
        "    \n",
        "    path ← reconstructPath(parent, start, end)\n",
        "    RETURN path, distance[end]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. BFS Grid Shortest Path\n",
        "\n",
        "### Time Complexity: O(R × C) | Space Complexity: O(R × C)\n",
        "\n",
        "```\n",
        "// GRID BFS - 4 DIRECTIONAL MOVEMENT\n",
        "// Direction vectors for up, down, left, right\n",
        "CONSTANT DIRECTIONS ← [(−1,0), (1,0), (0,−1), (0,1)]\n",
        "\n",
        "FUNCTION gridBFS(grid, startRow, startCol, endRow, endCol):\n",
        "    rows ← grid.rows\n",
        "    cols ← grid.cols\n",
        "    \n",
        "    // Validation\n",
        "    IF grid[startRow][startCol] = BLOCKED OR\n",
        "       grid[endRow][endCol] = BLOCKED:\n",
        "        RETURN -1\n",
        "    \n",
        "    visited ← 2D array [rows][cols], initialized to FALSE\n",
        "    queue ← empty queue\n",
        "    \n",
        "    queue.enqueue((startRow, startCol, 0))  // (row, col, distance)\n",
        "    visited[startRow][startCol] ← TRUE\n",
        "    \n",
        "    WHILE queue is NOT empty:\n",
        "        row, col, dist ← queue.dequeue()\n",
        "        \n",
        "        // Goal check\n",
        "        IF row = endRow AND col = endCol:\n",
        "            RETURN dist\n",
        "        \n",
        "        // Explore neighbors\n",
        "        FOR each (dr, dc) IN DIRECTIONS:\n",
        "            newRow ← row + dr\n",
        "            newCol ← col + dc\n",
        "            \n",
        "            // Boundary and validity check\n",
        "            IF newRow >= 0 AND newRow < rows AND\n",
        "               newCol >= 0 AND newCol < cols AND\n",
        "               NOT visited[newRow][newCol] AND\n",
        "               grid[newRow][newCol] ≠ BLOCKED:\n",
        "                \n",
        "                visited[newRow][newCol] ← TRUE\n",
        "                queue.enqueue((newRow, newCol, dist + 1))\n",
        "    \n",
        "    RETURN -1  // No path found\n",
        "\n",
        "// GRID BFS - 8 DIRECTIONAL MOVEMENT\n",
        "CONSTANT DIRECTIONS_8 ← [\n",
        "    (−1,0), (1,0), (0,−1), (0,1),     // Cardinal\n",
        "    (−1,−1), (−1,1), (1,−1), (1,1)    // Diagonal\n",
        "]\n",
        "\n",
        "// Same algorithm, use DIRECTIONS_8 instead\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Topological Sort\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// TOPOLOGICAL SORT - DFS (Kahn's Alternative Below)\n",
        "// Precondition: Graph must be a DAG (Directed Acyclic Graph)\n",
        "// Use case: Task scheduling, dependency resolution\n",
        "FUNCTION topologicalSort_DFS(graph):\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    stack ← empty stack\n",
        "    \n",
        "    FUNCTION dfs(node):\n",
        "        visited[node] ← TRUE\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            IF NOT visited[neighbor]:\n",
        "                dfs(neighbor)\n",
        "        \n",
        "        stack.push(node)  // Post-order insertion\n",
        "    \n",
        "    FOR each vertex v IN graph:\n",
        "        IF NOT visited[v]:\n",
        "            dfs(v)\n",
        "    \n",
        "    // Reverse stack to get topological order\n",
        "    result ← empty list\n",
        "    WHILE stack is NOT empty:\n",
        "        result.append(stack.pop())\n",
        "    \n",
        "    RETURN result\n",
        "\n",
        "// TOPOLOGICAL SORT - KAHN'S ALGORITHM (BFS-based)\n",
        "// Advantage: Detects cycles, easier to understand\n",
        "FUNCTION topologicalSort_Kahn(graph):\n",
        "    inDegree ← array of size V, initialized to 0\n",
        "    \n",
        "    // Calculate in-degrees\n",
        "    FOR each vertex u IN graph:\n",
        "        FOR each neighbor v IN graph.getNeighbors(u):\n",
        "            inDegree[v] ← inDegree[v] + 1\n",
        "    \n",
        "    queue ← empty queue\n",
        "    FOR each vertex v IN graph:\n",
        "        IF inDegree[v] = 0:\n",
        "            queue.enqueue(v)\n",
        "    \n",
        "    result ← empty list\n",
        "    \n",
        "    WHILE queue is NOT empty:\n",
        "        node ← queue.dequeue()\n",
        "        result.append(node)\n",
        "        \n",
        "        FOR each neighbor IN graph.getNeighbors(node):\n",
        "            inDegree[neighbor] ← inDegree[neighbor] − 1\n",
        "            IF inDegree[neighbor] = 0:\n",
        "                queue.enqueue(neighbor)\n",
        "    \n",
        "    // Cycle detection\n",
        "    IF result.size ≠ V:\n",
        "        RETURN NULL  // Cycle exists, no valid ordering\n",
        "    \n",
        "    RETURN result\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Shortest/Longest Path on DAG\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// SHORTEST PATH ON DAG\n",
        "// Advantage over Dijkstra: O(V+E) vs O((V+E)logV), handles negative weights\n",
        "FUNCTION shortestPathDAG(graph, source):\n",
        "    topOrder ← topologicalSort_DFS(graph)\n",
        "    \n",
        "    IF topOrder = NULL:\n",
        "        ERROR \"Graph contains cycle\"\n",
        "    \n",
        "    dist ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    dist[source] ← 0\n",
        "    \n",
        "    FOR each node IN topOrder:\n",
        "        IF dist[node] ≠ INFINITY:\n",
        "            FOR each (neighbor, weight) IN graph.getNeighbors(node):\n",
        "                IF dist[node] + weight < dist[neighbor]:\n",
        "                    dist[neighbor] ← dist[node] + weight\n",
        "                    parent[neighbor] ← node\n",
        "    \n",
        "    RETURN dist, parent\n",
        "\n",
        "// LONGEST PATH ON DAG\n",
        "// Method: Negate all weights, find shortest path, negate result\n",
        "// Alternative: Modify relaxation condition\n",
        "FUNCTION longestPathDAG(graph, source):\n",
        "    topOrder ← topologicalSort_DFS(graph)\n",
        "    \n",
        "    dist ← array of size V, initialized to -INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    dist[source] ← 0\n",
        "    \n",
        "    FOR each node IN topOrder:\n",
        "        IF dist[node] ≠ -INFINITY:\n",
        "            FOR each (neighbor, weight) IN graph.getNeighbors(node):\n",
        "                // Maximize instead of minimize\n",
        "                IF dist[node] + weight > dist[neighbor]:\n",
        "                    dist[neighbor] ← dist[node] + weight\n",
        "                    parent[neighbor] ← node\n",
        "    \n",
        "    RETURN dist, parent\n",
        "\n",
        "// CRITICAL PATH METHOD (Project Scheduling)\n",
        "FUNCTION criticalPath(tasks, dependencies):\n",
        "    // Build DAG from dependencies\n",
        "    graph ← buildDAG(tasks, dependencies)\n",
        "    \n",
        "    // Find longest path from virtual start to virtual end\n",
        "    longestPath ← longestPathDAG(graph, virtualStart)\n",
        "    \n",
        "    RETURN longestPath[virtualEnd]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Dijkstra's Algorithm\n",
        "\n",
        "### Time Complexity: O((V + E) log V) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// DIJKSTRA'S ALGORITHM - Priority Queue Implementation\n",
        "// Precondition: No negative edge weights\n",
        "// Use case: Single-source shortest path in weighted graphs\n",
        "FUNCTION dijkstra(graph, source):\n",
        "    dist ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    \n",
        "    // Min-heap: (distance, vertex)\n",
        "    pq ← empty min priority queue\n",
        "    \n",
        "    dist[source] ← 0\n",
        "    pq.insert((0, source))\n",
        "    \n",
        "    WHILE pq is NOT empty:\n",
        "        currentDist, u ← pq.extractMin()\n",
        "        \n",
        "        // Skip if already processed with better distance\n",
        "        IF visited[u]:\n",
        "            CONTINUE\n",
        "        visited[u] ← TRUE\n",
        "        \n",
        "        // Early termination optimization (if target known)\n",
        "        // IF u = target: RETURN dist[u]\n",
        "        \n",
        "        FOR each (v, weight) IN graph.getNeighbors(u):\n",
        "            IF NOT visited[v]:\n",
        "                newDist ← dist[u] + weight\n",
        "                \n",
        "                IF newDist < dist[v]:\n",
        "                    dist[v] ← newDist\n",
        "                    parent[v] ← u\n",
        "                    pq.insert((newDist, v))\n",
        "    \n",
        "    RETURN dist, parent\n",
        "\n",
        "// DIJKSTRA WITH DECREASE-KEY (Indexed Priority Queue)\n",
        "// More memory efficient, avoids duplicate entries\n",
        "FUNCTION dijkstra_IPQ(graph, source):\n",
        "    dist ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    \n",
        "    ipq ← empty indexed min priority queue\n",
        "    \n",
        "    dist[source] ← 0\n",
        "    ipq.insert(source, 0)\n",
        "    \n",
        "    WHILE ipq is NOT empty:\n",
        "        u ← ipq.extractMinIndex()\n",
        "        \n",
        "        FOR each (v, weight) IN graph.getNeighbors(u):\n",
        "            newDist ← dist[u] + weight\n",
        "            \n",
        "            IF newDist < dist[v]:\n",
        "                dist[v] ← newDist\n",
        "                parent[v] ← u\n",
        "                \n",
        "                IF ipq.contains(v):\n",
        "                    ipq.decreaseKey(v, newDist)\n",
        "                ELSE:\n",
        "                    ipq.insert(v, newDist)\n",
        "    \n",
        "    RETURN dist, parent\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Bellman-Ford Algorithm\n",
        "\n",
        "### Time Complexity: O(V × E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// BELLMAN-FORD ALGORITHM\n",
        "// Advantage: Handles negative weights, detects negative cycles\n",
        "// Use case: Arbitrage detection, routing protocols\n",
        "FUNCTION bellmanFord(graph, source):\n",
        "    dist ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    \n",
        "    dist[source] ← 0\n",
        "    \n",
        "    // Relax all edges V-1 times\n",
        "    FOR i FROM 1 TO V-1:\n",
        "        FOR each edge (u, v, weight) IN graph.edges:\n",
        "            IF dist[u] ≠ INFINITY AND dist[u] + weight < dist[v]:\n",
        "                dist[v] ← dist[u] + weight\n",
        "                parent[v] ← u\n",
        "    \n",
        "    // Detect negative cycle (V-th iteration)\n",
        "    FOR each edge (u, v, weight) IN graph.edges:\n",
        "        IF dist[u] ≠ INFINITY AND dist[u] + weight < dist[v]:\n",
        "            RETURN NULL, \"Negative cycle detected\"\n",
        "    \n",
        "    RETURN dist, parent\n",
        "\n",
        "// BELLMAN-FORD WITH NEGATIVE CYCLE IDENTIFICATION\n",
        "FUNCTION bellmanFord_FindCycle(graph, source):\n",
        "    dist ← array of size V, initialized to INFINITY\n",
        "    parent ← array of size V, initialized to -1\n",
        "    \n",
        "    dist[source] ← 0\n",
        "    \n",
        "    FOR i FROM 1 TO V-1:\n",
        "        FOR each edge (u, v, weight) IN graph.edges:\n",
        "            IF dist[u] ≠ INFINITY AND dist[u] + weight < dist[v]:\n",
        "                dist[v] ← dist[u] + weight\n",
        "                parent[v] ← u\n",
        "    \n",
        "    // Find vertex in negative cycle\n",
        "    cycleVertex ← -1\n",
        "    FOR each edge (u, v, weight) IN graph.edges:\n",
        "        IF dist[u] ≠ INFINITY AND dist[u] + weight < dist[v]:\n",
        "            cycleVertex ← v\n",
        "            BREAK\n",
        "    \n",
        "    IF cycleVertex = -1:\n",
        "        RETURN dist, parent, NULL\n",
        "    \n",
        "    // Trace back to find cycle\n",
        "    // Go back V times to ensure we're in the cycle\n",
        "    FOR i FROM 1 TO V:\n",
        "        cycleVertex ← parent[cycleVertex]\n",
        "    \n",
        "    cycle ← empty list\n",
        "    current ← cycleVertex\n",
        "    REPEAT:\n",
        "        cycle.prepend(current)\n",
        "        current ← parent[current]\n",
        "    UNTIL current = cycleVertex\n",
        "    cycle.prepend(cycleVertex)\n",
        "    \n",
        "    RETURN dist, parent, cycle\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Floyd-Warshall Algorithm\n",
        "\n",
        "### Time Complexity: O(V³) | Space Complexity: O(V²)\n",
        "\n",
        "```\n",
        "// FLOYD-WARSHALL ALL-PAIRS SHORTEST PATH\n",
        "// Use case: Dense graphs, all pairs needed, small V\n",
        "// Advantage: Simple, handles negative weights\n",
        "FUNCTION floydWarshall(graph):\n",
        "    n ← graph.vertexCount\n",
        "    \n",
        "    // Initialize distance matrix\n",
        "    dist ← 2D array [n][n]\n",
        "    next ← 2D array [n][n], initialized to -1\n",
        "    \n",
        "    FOR i FROM 0 TO n-1:\n",
        "        FOR j FROM 0 TO n-1:\n",
        "            IF i = j:\n",
        "                dist[i][j] ← 0\n",
        "            ELSE IF edge(i,j) exists:\n",
        "                dist[i][j] ← weight(i, j)\n",
        "                next[i][j] ← j\n",
        "            ELSE:\n",
        "                dist[i][j] ← INFINITY\n",
        "    \n",
        "    // Main algorithm - triple nested loop\n",
        "    FOR k FROM 0 TO n-1:        // Intermediate vertex\n",
        "        FOR i FROM 0 TO n-1:     // Source\n",
        "            FOR j FROM 0 TO n-1: // Destination\n",
        "                IF dist[i][k] ≠ INFINITY AND\n",
        "                   dist[k][j] ≠ INFINITY AND\n",
        "                   dist[i][k] + dist[k][j] < dist[i][j]:\n",
        "                    dist[i][j] ← dist[i][k] + dist[k][j]\n",
        "                    next[i][j] ← next[i][k]\n",
        "    \n",
        "    // Detect negative cycles\n",
        "    FOR i FROM 0 TO n-1:\n",
        "        IF dist[i][i] < 0:\n",
        "            RETURN NULL, \"Negative cycle detected\"\n",
        "    \n",
        "    RETURN dist, next\n",
        "\n",
        "// PATH RECONSTRUCTION\n",
        "FUNCTION getPath_FloydWarshall(next, u, v):\n",
        "    IF next[u][v] = -1:\n",
        "        RETURN NULL  // No path\n",
        "    \n",
        "    path ← [u]\n",
        "    WHILE u ≠ v:\n",
        "        u ← next[u][v]\n",
        "        path.append(u)\n",
        "    \n",
        "    RETURN path\n",
        "\n",
        "// TRANSITIVE CLOSURE (Warshall's Algorithm)\n",
        "FUNCTION transitiveClosure(graph):\n",
        "    n ← graph.vertexCount\n",
        "    reach ← 2D boolean array [n][n]\n",
        "    \n",
        "    // Initialize\n",
        "    FOR i FROM 0 TO n-1:\n",
        "        FOR j FROM 0 TO n-1:\n",
        "            reach[i][j] ← (i = j) OR edge(i,j) exists\n",
        "    \n",
        "    FOR k FROM 0 TO n-1:\n",
        "        FOR i FROM 0 TO n-1:\n",
        "            FOR j FROM 0 TO n-1:\n",
        "                reach[i][j] ← reach[i][j] OR\n",
        "                              (reach[i][k] AND reach[k][j])\n",
        "    \n",
        "    RETURN reach\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Bridges and Articulation Points\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// BRIDGES - Edges whose removal disconnects graph\n",
        "// ARTICULATION POINTS - Vertices whose removal disconnects graph\n",
        "// Based on Tarjan's DFS with discovery and low-link values\n",
        "\n",
        "FUNCTION findBridgesAndArticulationPoints(graph):\n",
        "    n ← graph.vertexCount\n",
        "    visited ← array of size n, initialized to FALSE\n",
        "    disc ← array of size n      // Discovery time\n",
        "    low ← array of size n       // Lowest reachable\n",
        "    parent ← array of size n, initialized to -1\n",
        "    timer ← 0\n",
        "    \n",
        "    bridges ← empty list\n",
        "    articulationPoints ← empty set\n",
        "    \n",
        "    FUNCTION dfs(u):\n",
        "        timer ← timer + 1\n",
        "        disc[u] ← timer\n",
        "        low[u] ← timer\n",
        "        visited[u] ← TRUE\n",
        "        childCount ← 0\n",
        "        \n",
        "        FOR each neighbor v IN graph.getNeighbors(u):\n",
        "            IF NOT visited[v]:\n",
        "                childCount ← childCount + 1\n",
        "                parent[v] ← u\n",
        "                dfs(v)\n",
        "                \n",
        "                // Update low value\n",
        "                low[u] ← min(low[u], low[v])\n",
        "                \n",
        "                // BRIDGE CONDITION\n",
        "                // If low[v] > disc[u], edge (u,v) is a bridge\n",
        "                IF low[v] > disc[u]:\n",
        "                    bridges.append((u, v))\n",
        "                \n",
        "                // ARTICULATION POINT CONDITIONS\n",
        "                // Case 1: u is root with 2+ children\n",
        "                IF parent[u] = -1 AND childCount >= 2:\n",
        "                    articulationPoints.add(u)\n",
        "                \n",
        "                // Case 2: u is not root and low[v] >= disc[u]\n",
        "                IF parent[u] ≠ -1 AND low[v] >= disc[u]:\n",
        "                    articulationPoints.add(u)\n",
        "            \n",
        "            ELSE IF v ≠ parent[u]:\n",
        "                // Back edge - update low value\n",
        "                low[u] ← min(low[u], disc[v])\n",
        "    \n",
        "    // Handle disconnected components\n",
        "    FOR each vertex v IN graph:\n",
        "        IF NOT visited[v]:\n",
        "            dfs(v)\n",
        "    \n",
        "    RETURN bridges, articulationPoints\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Tarjan's SCC Algorithm\n",
        "\n",
        "### Time Complexity: O(V + E) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// TARJAN'S STRONGLY CONNECTED COMPONENTS\n",
        "// SCC: Maximal set where every vertex is reachable from every other\n",
        "// Use case: 2-SAT, dependency analysis, graph condensation\n",
        "\n",
        "FUNCTION tarjanSCC(graph):\n",
        "    n ← graph.vertexCount\n",
        "    disc ← array of size n, initialized to -1\n",
        "    low ← array of size n\n",
        "    onStack ← array of size n, initialized to FALSE\n",
        "    stack ← empty stack\n",
        "    timer ← 0\n",
        "    \n",
        "    sccs ← empty list  // List of SCCs\n",
        "    \n",
        "    FUNCTION dfs(u):\n",
        "        timer ← timer + 1\n",
        "        disc[u] ← timer\n",
        "        low[u] ← timer\n",
        "        stack.push(u)\n",
        "        onStack[u] ← TRUE\n",
        "        \n",
        "        FOR each neighbor v IN graph.getNeighbors(u):\n",
        "            IF disc[v] = -1:  // Not visited\n",
        "                dfs(v)\n",
        "                low[u] ← min(low[u], low[v])\n",
        "            ELSE IF onStack[v]:  // Back edge to stack vertex\n",
        "                low[u] ← min(low[u], disc[v])\n",
        "        \n",
        "        // If u is root of SCC\n",
        "        IF low[u] = disc[u]:\n",
        "            scc ← empty list\n",
        "            REPEAT:\n",
        "                v ← stack.pop()\n",
        "                onStack[v] ← FALSE\n",
        "                scc.append(v)\n",
        "            UNTIL v = u\n",
        "            sccs.append(scc)\n",
        "    \n",
        "    FOR each vertex v IN graph:\n",
        "        IF disc[v] = -1:\n",
        "            dfs(v)\n",
        "    \n",
        "    RETURN sccs\n",
        "\n",
        "// KOSARAJU'S ALGORITHM (Alternative)\n",
        "FUNCTION kosarajuSCC(graph):\n",
        "    // Step 1: Get finish order via DFS\n",
        "    visited ← array of size V, initialized to FALSE\n",
        "    finishOrder ← empty stack\n",
        "    \n",
        "    FUNCTION dfs1(u):\n",
        "        visited[u] ← TRUE\n",
        "        FOR each v IN graph.getNeighbors(u):\n",
        "            IF NOT visited[v]:\n",
        "                dfs1(v)\n",
        "        finishOrder.push(u)\n",
        "    \n",
        "    FOR each v IN graph:\n",
        "        IF NOT visited[v]:\n",
        "            dfs1(v)\n",
        "    \n",
        "    // Step 2: Transpose graph\n",
        "    transposed ← transpose(graph)\n",
        "    \n",
        "    // Step 3: DFS on transposed in reverse finish order\n",
        "    visited ← reset to FALSE\n",
        "    sccs ← empty list\n",
        "    \n",
        "    FUNCTION dfs2(u, scc):\n",
        "        visited[u] ← TRUE\n",
        "        scc.append(u)\n",
        "        FOR each v IN transposed.getNeighbors(u):\n",
        "            IF NOT visited[v]:\n",
        "                dfs2(v, scc)\n",
        "    \n",
        "    WHILE finishOrder NOT empty:\n",
        "        u ← finishOrder.pop()\n",
        "        IF NOT visited[u]:\n",
        "            scc ← empty list\n",
        "            dfs2(u, scc)\n",
        "            sccs.append(scc)\n",
        "    \n",
        "    RETURN sccs\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Travelling Salesman Problem (DP)\n",
        "\n",
        "### Time Complexity: O(n² × 2ⁿ) | Space Complexity: O(n × 2ⁿ)\n",
        "\n",
        "```\n",
        "// TSP WITH DYNAMIC PROGRAMMING (Held-Karp Algorithm)\n",
        "// Problem: Find minimum cost Hamiltonian cycle\n",
        "// Precondition: n ≤ 20 (exponential complexity)\n",
        "\n",
        "FUNCTION tsp_DP(dist):\n",
        "    n ← dist.rows\n",
        "    FULL_MASK ← (1 << n) - 1  // All cities visited\n",
        "    \n",
        "    // dp[mask][i] = min cost to reach city i having visited cities in mask\n",
        "    dp ← 2D array [2^n][n], initialized to INFINITY\n",
        "    parent ← 2D array [2^n][n], initialized to -1\n",
        "    \n",
        "    // Base case: start at city 0\n",
        "    dp[1][0] ← 0\n",
        "    \n",
        "    FOR mask FROM 1 TO FULL_MASK:\n",
        "        FOR last FROM 0 TO n-1:\n",
        "            // Check if last city is in mask\n",
        "            IF (mask & (1 << last)) = 0:\n",
        "                CONTINUE\n",
        "            IF dp[mask][last] = INFINITY:\n",
        "                CONTINUE\n",
        "            \n",
        "            // Try extending to unvisited cities\n",
        "            FOR next FROM 0 TO n-1:\n",
        "                IF (mask & (1 << next)) ≠ 0:\n",
        "                    CONTINUE  // Already visited\n",
        "                \n",
        "                newMask ← mask | (1 << next)\n",
        "                newCost ← dp[mask][last] + dist[last][next]\n",
        "                \n",
        "                IF newCost < dp[newMask][next]:\n",
        "                    dp[newMask][next] ← newCost\n",
        "                    parent[newMask][next] ← last\n",
        "    \n",
        "    // Find minimum cost to complete cycle\n",
        "    minCost ← INFINITY\n",
        "    lastCity ← -1\n",
        "    \n",
        "    FOR i FROM 1 TO n-1:\n",
        "        cost ← dp[FULL_MASK][i] + dist[i][0]\n",
        "        IF cost < minCost:\n",
        "            minCost ← cost\n",
        "            lastCity ← i\n",
        "    \n",
        "    // Reconstruct path\n",
        "    path ← reconstructTSPPath(parent, FULL_MASK, lastCity)\n",
        "    path.append(0)\n",
        "    \n",
        "    RETURN minCost, path\n",
        "\n",
        "FUNCTION reconstructTSPPath(parent, mask, last):\n",
        "    path ← empty list\n",
        "    \n",
        "    WHILE mask ≠ 0:\n",
        "        path.prepend(last)\n",
        "        prevLast ← parent[mask][last]\n",
        "        mask ← mask XOR (1 << last)\n",
        "        last ← prevLast\n",
        "    \n",
        "    RETURN path\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Eulerian Paths and Circuits\n",
        "\n",
        "### Time Complexity: O(E) | Space Complexity: O(V + E)\n",
        "\n",
        "```\n",
        "// EULERIAN PATH: Visits every EDGE exactly once\n",
        "// EULERIAN CIRCUIT: Eulerian path that starts and ends at same vertex\n",
        "\n",
        "// EXISTENCE CONDITIONS\n",
        "FUNCTION checkEulerianExistence(graph, isDirected):\n",
        "    IF isDirected:\n",
        "        inDegree ← array of size V, initialized to 0\n",
        "        outDegree ← array of size V, initialized to 0\n",
        "        \n",
        "        FOR each edge (u, v) IN graph:\n",
        "            outDegree[u] ← outDegree[u] + 1\n",
        "            inDegree[v] ← inDegree[v] + 1\n",
        "        \n",
        "        startNodes ← 0  // out - in = 1\n",
        "        endNodes ← 0    // in - out = 1\n",
        "        \n",
        "        FOR each vertex v:\n",
        "            diff ← outDegree[v] - inDegree[v]\n",
        "            IF diff > 1 OR diff < -1:\n",
        "                RETURN \"NONE\"\n",
        "            IF diff = 1:\n",
        "                startNodes ← startNodes + 1\n",
        "            IF diff = -1:\n",
        "                endNodes ← endNodes + 1\n",
        "        \n",
        "        IF startNodes = 0 AND endNodes = 0:\n",
        "            RETURN \"CIRCUIT\"\n",
        "        IF startNodes = 1 AND endNodes = 1:\n",
        "            RETURN \"PATH\"\n",
        "        RETURN \"NONE\"\n",
        "    \n",
        "    ELSE:  // Undirected\n",
        "        oddDegree ← 0\n",
        "        FOR each vertex v:\n",
        "            IF degree(v) is ODD:\n",
        "                oddDegree ← oddDegree + 1\n",
        "        \n",
        "        IF oddDegree = 0:\n",
        "            RETURN \"CIRCUIT\"\n",
        "        IF oddDegree = 2:\n",
        "            RETURN \"PATH\"\n",
        "        RETURN \"NONE\"\n",
        "\n",
        "// HIERHOLZER'S ALGORITHM - Find Eulerian Path/Circuit\n",
        "FUNCTION findEulerianPath(graph, isDirected):\n",
        "    // Step 1: Check existence and find start vertex\n",
        "    eulerType ← checkEulerianExistence(graph, isDirected)\n",
        "    \n",
        "    IF eulerType = \"NONE\":\n",
        "        RETURN NULL\n",
        "    \n",
        "    // Find start vertex\n",
        "    IF eulerType = \"PATH\":\n",
        "        IF isDirected:\n",
        "            start ← vertex with outDegree - inDegree = 1\n",
        "        ELSE:\n",
        "            start ← vertex with odd degree\n",
        "    ELSE:\n",
        "        start ← any vertex with degree > 0\n",
        "    \n",
        "    // Step 2: Hierholzer's algorithm\n",
        "    edgeCount ← copy of adjacency list sizes\n",
        "    path ← empty list\n",
        "    stack ← empty stack\n",
        "    stack.push(start)\n",
        "    \n",
        "    WHILE stack NOT empty:\n",
        "        u ← stack.top()\n",
        "        \n",
        "        IF edgeCount[u] = 0:\n",
        "            path.prepend(u)\n",
        "            stack.pop()\n",
        "        ELSE:\n",
        "            v ← graph.adj[u][edgeCount[u] - 1]\n",
        "            edgeCount[u] ← edgeCount[u] - 1\n",
        "            \n",
        "            IF NOT isDirected:\n",
        "                // Remove reverse edge for undirected\n",
        "                removeEdge(edgeCount, v, u)\n",
        "            \n",
        "            stack.push(v)\n",
        "    \n",
        "    RETURN path\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 14. Prim's MST Algorithm\n",
        "\n",
        "### Time Complexity: O((V + E) log V) | Space Complexity: O(V)\n",
        "\n",
        "```\n",
        "// PRIM'S MST - LAZY IMPLEMENTATION\n",
        "// Use case: Finding minimum spanning tree\n",
        "// Works for: Connected, undirected, weighted graphs\n",
        "\n",
        "FUNCTION primMST_Lazy(graph, start):\n",
        "    n ← graph.vertexCount\n",
        "    visited ← array of size n, initialized to FALSE\n",
        "    mstEdges ← empty list\n",
        "    mstCost ← 0\n",
        "    \n",
        "    // Min-heap: (weight, from, to)\n",
        "    pq ← empty min priority queue\n",
        "    \n",
        "    FUNCTION addEdges(node):\n",
        "        visited[node] ← TRUE\n",
        "        FOR each (neighbor, weight) IN graph.getNeighbors(node):\n",
        "            IF NOT visited[neighbor]:\n",
        "                pq.insert((weight, node, neighbor))\n",
        "    \n",
        "    addEdges(start)\n",
        "    edgeCount ← 0\n",
        "    \n",
        "    WHILE pq NOT empty AND edgeCount < n - 1:\n",
        "        weight, from, to ← pq.extractMin()\n",
        "        \n",
        "        IF visited[to]:\n",
        "            CONTINUE  // Skip stale edges\n",
        "        \n",
        "        mstEdges.append((from, to, weight))\n",
        "        mstCost ← mstCost + weight\n",
        "        edgeCount ← edgeCount + 1\n",
        "        \n",
        "        addEdges(to)\n",
        "    \n",
        "    IF edgeCount ≠ n - 1:\n",
        "        RETURN NULL, \"Graph is not connected\"\n",
        "    \n",
        "    RETURN mstEdges, mstCost\n",
        "\n",
        "// PRIM'S MST - EAGER IMPLEMENTATION (Indexed Priority Queue)\n",
        "// More efficient: O((V + E) log V) with better constants\n",
        "\n",
        "FUNCTION primMST_Eager(graph, start):\n",
        "    n ← graph.vertexCount\n",
        "    visited ← array of size n, initialized to FALSE\n",
        "    minEdge ← array of size n, initialized to (INFINITY, -1)\n",
        "    \n",
        "    ipq ← empty indexed min priority queue\n",
        "    mstEdges ← empty list\n",
        "    mstCost ← 0\n",
        "    \n",
        "    minEdge[start] ← (0, -1)\n",
        "    ipq.insert(start, 0)\n",
        "    \n",
        "    WHILE ipq NOT empty:\n",
        "        u ← ipq.extractMinIndex()\n",
        "        weight, from ← minEdge[u]\n",
        "        visited[u] ← TRUE\n",
        "        \n",
        "        IF from ≠ -1:\n",
        "            mstEdges.append((from, u, weight))\n",
        "            mstCost ← mstCost + weight\n",
        "        \n",
        "        FOR each (v, w) IN graph.getNeighbors(u):\n",
        "            IF visited[v]:\n",
        "                CONTINUE\n",
        "            \n",
        "            IF w < minEdge[v].weight:\n",
        "                minEdge[v] ← (w, u)\n",
        "                \n",
        "                IF ipq.contains(v):\n",
        "                    ipq.decreaseKey(v, w)\n",
        "                ELSE:\n",
        "                    ipq.insert(v, w)\n",
        "    \n",
        "    RETURN mstEdges, mstCost\n",
        "\n",
        "// KRUSKAL'S MST (Alternative using Union-Find)\n",
        "FUNCTION kruskalMST(graph):\n",
        "    edges ← sort all edges by weight ascending\n",
        "    uf ← UnionFind(V)\n",
        "    mstEdges ← empty list\n",
        "    mstCost ← 0\n",
        "    \n",
        "    FOR each (u, v, weight) IN edges:\n",
        "        IF uf.find(u) ≠ uf.find(v):\n",
        "            uf.union(u, v)\n",
        "            mstEdges.append((u, v, weight))\n",
        "            mstCost ← mstCost + weight\n",
        "            \n",
        "            IF mstEdges.size = V - 1:\n",
        "                BREAK\n",
        "    \n",
        "    RETURN mstEdges, mstCost\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 15. Max Flow Ford-Fulkerson\n",
        "\n",
        "### Time Complexity: O(E × maxFlow) | Space Complexity: O(V²)\n",
        "\n",
        "```\n",
        "// FORD-FULKERSON METHOD (DFS-based)\n",
        "// Use case: Maximum flow in a network\n",
        "// Note: May not terminate with irrational capacities\n",
        "\n",
        "FUNCTION fordFulkerson(graph, source, sink):\n",
        "    n ← graph.vertexCount\n",
        "    \n",
        "    // Residual graph: capacity[u][v] = remaining capacity\n",
        "    capacity ← copy of graph capacity matrix\n",
        "    \n",
        "    maxFlow ← 0\n",
        "    \n",
        "    // Find augmenting path using DFS\n",
        "    FUNCTION findPath(s, t, parent):\n",
        "        visited ← array of size n, initialized to FALSE\n",
        "        visited[s] ← TRUE\n",
        "        stack ← [(s, INFINITY)]\n",
        "        \n",
        "        WHILE stack NOT empty:\n",
        "            u, flow ← stack.pop()\n",
        "            \n",
        "            FOR v FROM 0 TO n-1:\n",
        "                IF NOT visited[v] AND capacity[u][v] > 0:\n",
        "                    visited[v] ← TRUE\n",
        "                    parent[v] ← u\n",
        "                    newFlow ← min(flow, capacity[u][v])\n",
        "                    \n",
        "                    IF v = t:\n",
        "                        RETURN newFlow\n",
        "                    \n",
        "                    stack.push((v, newFlow))\n",
        "        \n",
        "        RETURN 0\n",
        "    \n",
        "    parent ← array of size n\n",
        "    \n",
        "    WHILE TRUE:\n",
        "        pathFlow ← findPath(source, sink, parent)\n",
        "        \n",
        "        IF pathFlow = 0:\n",
        "            BREAK\n",
        "        \n",
        "        maxFlow ← maxFlow + pathFlow\n",
        "        \n",
        "        // Update residual capacities\n",
        "        v ← sink\n",
        "        WHILE v ≠ source:\n",
        "            u ← parent[v]\n",
        "            capacity[u][v] ← capacity[u][v] - pathFlow\n",
        "            capacity[v][u] ← capacity[v][u] + pathFlow  // Reverse edge\n",
        "            v ← u\n",
        "    \n",
        "    RETURN maxFlow\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 16. Edmonds-Karp Algorithm\n",
        "\n",
        "### Time Complexity: O(V × E²) | Space Complexity: O(V²)\n",
        "\n",
        "```\n",
        "// EDMONDS-KARP (BFS-based Ford-Fulkerson)\n",
        "// Guaranteed polynomial time, finds shortest augmenting paths\n",
        "\n",
        "FUNCTION edmondsKarp(graph, source, sink):\n",
        "    n ← graph.vertexCount\n",
        "    capacity ← copy of graph capacity matrix\n",
        "    maxFlow ← 0\n",
        "    \n",
        "    FUNCTION bfs(s, t, parent):\n",
        "        visited ← array of size n, initialized to FALSE\n",
        "        visited[s] ← TRUE\n",
        "        queue ← empty queue\n",
        "        queue.enqueue((s, INFINITY))\n",
        "        \n",
        "        WHILE queue NOT empty:\n",
        "            u, flow ← queue.dequeue()\n",
        "            \n",
        "            FOR v FROM 0 TO n-1:\n",
        "                IF NOT visited[v] AND capacity[u][v] > 0:\n",
        "                    visited[v] ← TRUE\n",
        "                    parent[v] ← u\n",
        "                    newFlow ← min(flow, capacity[u][v])\n",
        "                    \n",
        "                    IF v = t:\n",
        "                        RETURN newFlow\n",
        "                    \n",
        "                    queue.enqueue((v, newFlow))\n",
        "        \n",
        "        RETURN 0\n",
        "    \n",
        "    parent ← array of size n\n",
        "    \n",
        "    WHILE TRUE:\n",
        "        pathFlow ← bfs(source, sink, parent)\n",
        "        \n",
        "        IF pathFlow = 0:\n",
        "            BREAK\n",
        "        \n",
        "        maxFlow ← maxFlow + pathFlow\n",
        "        \n",
        "        v ← sink\n",
        "        WHILE v ≠ source:\n",
        "            u ← parent[v]\n",
        "            capacity[u][v] ← capacity[u][v] - pathFlow\n",
        "            capacity[v][u] ← capacity[v][u] + pathFlow\n",
        "            v ← u\n",
        "    \n",
        "    RETURN maxFlow\n",
        "\n",
        "// MIN-CUT FROM MAX-FLOW\n",
        "FUNCTION findMinCut(graph, source, sink):\n",
        "    maxFlow ← edmondsKarp(graph, source, sink)\n",
        "    \n",
        "    // Find reachable vertices from source in residual graph\n",
        "    visited ← BFS from source in residual graph\n",
        "    \n",
        "    minCutEdges ← empty list\n",
        "    FOR each edge (u, v) IN original graph:\n",
        "        IF visited[u] AND NOT visited[v]:\n",
        "            minCutEdges.append((u, v))\n",
        "    \n",
        "    RETURN minCutEdges, maxFlow\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 17. Capacity Scaling\n",
        "\n",
        "### Time Complexity: O(E² log C) | Space Complexity: O(V²)\n",
        "\n",
        "```\n",
        "// CAPACITY SCALING - Improved Ford-Fulkerson\n",
        "// C = maximum edge capacity\n",
        "// Only considers edges with capacity >= delta\n",
        "\n",
        "FUNCTION capacityScaling(graph, source, sink):\n",
        "    n ← graph.vertexCount\n",
        "    capacity ← copy of graph capacity matrix\n",
        "    maxFlow ← 0\n",
        "    \n",
        "    // Find initial delta (largest power of 2 <= max capacity)\n",
        "    maxCap ← maximum edge capacity in graph\n",
        "    delta ← 1\n",
        "    WHILE delta * 2 <= maxCap:\n",
        "        delta ← delta * 2\n",
        "    \n",
        "    FUNCTION findPath(s, t, parent, minCap):\n",
        "        visited ← array of size n, initialized to FALSE\n",
        "        visited[s] ← TRUE\n",
        "        queue ← empty queue\n",
        "        queue.enqueue((s, INFINITY))\n",
        "        \n",
        "        WHILE queue NOT empty:\n",
        "            u, flow ← queue.dequeue()\n",
        "            \n",
        "            FOR v FROM 0 TO n-1:\n",
        "                // Only use edges with capacity >= minCap\n",
        "                IF NOT visited[v] AND capacity[u][v] >= minCap:\n",
        "                    visited[v] ← TRUE\n",
        "                    parent[v] ← u\n",
        "                    newFlow ← min(flow, capacity[u][v])\n",
        "                    \n",
        "                    IF v = t:\n",
        "                        RETURN newFlow\n",
        "                    \n",
        "                    queue.enqueue((v, newFlow))\n",
        "        \n",
        "        RETURN 0\n",
        "    \n",
        "    parent ← array of size n\n",
        "    \n",
        "    WHILE delta >= 1:\n",
        "        WHILE TRUE:\n",
        "            pathFlow ← findPath(source, sink, parent, delta)\n",
        "            \n",
        "            IF pathFlow = 0:\n",
        "                BREAK\n",
        "            \n",
        "            maxFlow ← maxFlow + pathFlow\n",
        "            \n",
        "            v ← sink\n",
        "            WHILE v ≠ source:\n",
        "                u ← parent[v]\n",
        "                capacity[u][v] ← capacity[u][v] - pathFlow\n",
        "                capacity[v][u] ← capacity[v][u] + pathFlow\n",
        "                v ← u\n",
        "        \n",
        "        delta ← delta / 2\n",
        "    \n",
        "    RETURN maxFlow\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 18. Dinic's Algorithm\n",
        "\n",
        "### Time Complexity: O(V² × E) | Space Complexity: O(V²)\n",
        "\n",
        "```\n",
        "// DINIC'S ALGORITHM - Blocking Flow Method\n",
        "// Key insight: Use level graph to find blocking flows\n",
        "// Best for: Unit capacity graphs O(E√V), bipartite matching O(E√V)\n",
        "\n",
        "FUNCTION dinic(graph, source, sink):\n",
        "    n ← graph.vertexCount\n",
        "    capacity ← build residual graph from edges\n",
        "    maxFlow ← 0\n",
        "    \n",
        "    // Build level graph using BFS\n",
        "    FUNCTION buildLevelGraph():\n",
        "        level ← array of size n, initialized to -1\n",
        "        level[source] ← 0\n",
        "        queue ← [source]\n",
        "        \n",
        "        WHILE queue NOT empty:\n",
        "            u ← queue.dequeue()\n",
        "            FOR each v with capacity[u][v] > 0:\n",
        "                IF level[v] = -1:\n",
        "                    level[v] ← level[u] + 1\n",
        "                    queue.enqueue(v)\n",
        "        \n",
        "        RETURN level[sink] ≠ -1\n",
        "    \n",
        "    // Send flow using DFS with pruning\n",
        "    FUNCTION sendFlow(u, pushed):\n",
        "        IF u = sink:\n",
        "            RETURN pushed\n",
        "        \n",
        "        WHILE iter[u] < n:\n",
        "            v ← iter[u]\n",
        "            \n",
        "            IF level[v] = level[u] + 1 AND capacity[u][v] > 0:\n",
        "                d ← sendFlow(v, min(pushed, capacity[u][v]))\n",
        "                \n",
        "                IF d > 0:\n",
        "                    capacity[u][v] ← capacity[u][v] - d\n",
        "                    capacity[v][u] ← capacity[v][u] + d\n",
        "                    RETURN d\n",
        "            \n",
        "            iter[u] ← iter[u] + 1\n",
        "        \n",
        "        RETURN 0\n",
        "    \n",
        "    WHILE buildLevelGraph():\n",
        "        iter ← array of size n, initialized to 0\n",
        "        \n",
        "        WHILE TRUE:\n",
        "            pushed ← sendFlow(source, INFINITY)\n",
        "            IF pushed = 0:\n",
        "                BREAK\n",
        "            maxFlow ← maxFlow + pushed\n",
        "    \n",
        "    RETURN maxFlow\n",
        "\n",
        "// DINIC WITH EDGE LIST (Memory Efficient)\n",
        "STRUCTURE Edge:\n",
        "    to, rev, cap, flow\n",
        "    \n",
        "FUNCTION dinic_EdgeList(n, edges, source, sink):\n",
        "    adj ← array of n empty lists\n",
        "    \n",
        "    FUNCTION addEdge(from, to, cap):\n",
        "        adj[from].append(Edge(to, adj[to].size, cap, 0))\n",
        "        adj[to].append(Edge(from, adj[from].size - 1, 0, 0))\n",
        "    \n",
        "    // Add all edges\n",
        "    FOR each (u, v, c) IN edges:\n",
        "        addEdge(u, v, c)\n",
        "    \n",
        "    // Rest of Dinic's algorithm...\n",
        "    // Use edge.cap - edge.flow for residual capacity\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 19. Bipartite Matching\n",
        "\n",
        "### Time Complexity: O(V × E) or O(E√V) with Hopcroft-Karp | Space: O(V)\n",
        "\n",
        "```\n",
        "// BIPARTITE MATCHING - Hungarian Algorithm / Kuhn's Algorithm\n",
        "// Problem: Maximum matching in bipartite graph\n",
        "\n",
        "FUNCTION maxBipartiteMatching(graph, leftSize, rightSize):\n",
        "    match ← array of size rightSize, initialized to -1\n",
        "    result ← 0\n",
        "    \n",
        "    // Try to find augmenting path from each left vertex\n",
        "    FUNCTION tryKuhn(v, visited):\n",
        "        FOR each u IN graph.getNeighbors(v):\n",
        "            IF NOT visited[u]:\n",
        "                visited[u] ← TRUE\n",
        "                \n",
        "                // If right vertex is unmatched or can find alternative\n",
        "                IF match[u] = -1 OR tryKuhn(match[u], visited):\n",
        "                    match[u] ← v\n",
        "                    RETURN TRUE\n",
        "        \n",
        "        RETURN FALSE\n",
        "    \n",
        "    FOR v FROM 0 TO leftSize - 1:\n",
        "        visited ← array of size rightSize, initialized to FALSE\n",
        "        IF tryKuhn(v, visited):\n",
        "            result ← result + 1\n",
        "    \n",
        "    RETURN result, match\n",
        "\n",
        "// HOPCROFT-KARP ALGORITHM - O(E√V)\n",
        "FUNCTION hopcroftKarp(graph, leftSize, rightSize):\n",
        "    matchL ← array of size leftSize, initialized to -1\n",
        "    matchR ← array of size rightSize, initialized to -1\n",
        "    dist ← array of size leftSize + 1\n",
        "    \n",
        "    FUNCTION bfs():\n",
        "        queue ← empty queue\n",
        "        \n",
        "        FOR u FROM 0 TO leftSize - 1:\n",
        "            IF matchL[u] = -1:\n",
        "                dist[u] ← 0\n",
        "                queue.enqueue(u)\n",
        "            ELSE:\n",
        "                dist[u] ← INFINITY\n",
        "        \n",
        "        dist[NIL] ← INFINITY\n",
        "        \n",
        "        WHILE queue NOT empty:\n",
        "            u ← queue.dequeue()\n",
        "            \n",
        "            IF dist[u] < dist[NIL]:\n",
        "                FOR each v IN graph.getNeighbors(u):\n",
        "                    IF dist[matchR[v] ?? NIL] = INFINITY:\n",
        "                        dist[matchR[v] ?? NIL] ← dist[u] + 1\n",
        "                        IF matchR[v] ≠ -1:\n",
        "                            queue.enqueue(matchR[v])\n",
        "        \n",
        "        RETURN dist[NIL] ≠ INFINITY\n",
        "    \n",
        "    FUNCTION dfs(u):\n",
        "        IF u = NIL:\n",
        "            RETURN TRUE\n",
        "        \n",
        "        FOR each v IN graph.getNeighbors(u):\n",
        "            IF dist[matchR[v] ?? NIL] = dist[u] + 1:\n",
        "                IF dfs(matchR[v] ?? NIL):\n",
        "                    matchR[v] ← u\n",
        "                    matchL[u] ← v\n",
        "                    RETURN TRUE\n",
        "        \n",
        "        dist[u] ← INFINITY\n",
        "        RETURN FALSE\n",
        "    \n",
        "    matching ← 0\n",
        "    \n",
        "    WHILE bfs():\n",
        "        FOR u FROM 0 TO leftSize - 1:\n",
        "            IF matchL[u] = -1 AND dfs(u):\n",
        "                matching ← matching + 1\n",
        "    \n",
        "    RETURN matching\n",
        "\n",
        "// MINIMUM VERTEX COVER (König's Theorem)\n",
        "// In bipartite graph: min vertex cover = max matching\n",
        "FUNCTION minVertexCover(graph, leftSize, rightSize):\n",
        "    matching, match ← maxBipartiteMatching(graph, leftSize, rightSize)\n",
        "    \n",
        "    // Apply König's theorem to find cover\n",
        "    // ... (BFS from unmatched left vertices)\n",
        "    \n",
        "    RETURN cover\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Reference Cheat Sheet\n",
        "\n",
        "| Algorithm | Time | Space | Use When |\n",
        "|-----------|------|-------|----------|\n",
        "| DFS | O(V+E) | O(V) | Path finding, cycle detection, connected components |\n",
        "| BFS | O(V+E) | O(V) | Shortest path (unweighted), level traversal |\n",
        "| Topological Sort | O(V+E) | O(V) | Task scheduling, DAG ordering |\n",
        "| Dijkstra | O((V+E)logV) | O(V) | Shortest path, non-negative weights |\n",
        "| Bellman-Ford | O(VE) | O(V) | Negative weights, cycle detection |\n",
        "| Floyd-Warshall | O(V³) | O(V²) | All-pairs shortest path, small graphs |\n",
        "| Tarjan SCC | O(V+E) | O(V) | Strongly connected components |\n",
        "| Bridges/AP | O(V+E) | O(V) | Network reliability, cut vertices |\n",
        "| TSP (DP) | O(n²2ⁿ) | O(n2ⁿ) | Optimal tour, n ≤ 20 |\n",
        "| Prim/Kruskal | O((V+E)logV) | O(V) | Minimum spanning tree |\n",
        "| Edmonds-Karp | O(VE²) | O(V²) | Maximum flow, general networks |\n",
        "| Dinic | O(V²E) | O(V²) | Max flow, unit capacity O(E√V) |\n",
        "| Hopcroft-Karp | O(E√V) | O(V) | Bipartite matching |\n",
        "\n",
        "---\n",
        "\n",
        "## Edge Cases Checklist\n",
        "\n",
        "```\n",
        "// ALWAYS HANDLE THESE EDGE CASES:\n",
        "\n",
        "□ Empty graph (V = 0 or E = 0)\n",
        "□ Single vertex graph\n",
        "□ Disconnected components\n",
        "□ Self-loops\n",
        "□ Parallel edges (multigraph)\n",
        "□ Negative edge weights\n",
        "□ Negative cycles\n",
        "□ Source equals destination\n",
        "□ No path exists\n",
        "□ Integer overflow in distance calculations\n",
        "□ Graph with only one edge\n",
        "□ Complete graph (E = V²)\n",
        "□ Tree (E = V - 1)\n",
        "□ Bipartite vs non-bipartite\n",
        "□ Directed vs undirected edge interpretation\n",
        "```\n"
      ],
      "metadata": {
        "id": "SyXvND_L2Ryf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pgpWWN1y2PeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CO0moLTB2PSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qg7scCfW2My9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive Directed Acyclic Graph Execution Engine (ADAGE)\n",
        "## First-of-Kind Background Task Pipeline Architecture\n",
        "\n",
        "---\n",
        "\n",
        "# TABLE OF CONTENTS\n",
        "\n",
        "\n",
        "===============================================================\n",
        "### SECTION 0: DOCUMENT STRUCTURE\n",
        "===============================================================\n",
        "\n",
        "This README defines a revolutionary background task orchestration system\n",
        "that transcends current SOTA solutions (Airflow, Temporal, Prefect, Dagster)\n",
        "by introducing adaptive runtime optimization, speculative execution, and\n",
        "self-healing flow graphs with predictive resource allocation.\n",
        "\n",
        "Key Innovation: Compile-Time + Runtime Hybrid Optimization with\n",
        "Criticality-Weighted Priority Scheduling and Speculative Dependency Resolution\n",
        "=============================================================================\n",
        "\n",
        "\n",
        "1. [Core Philosophy & Innovation](#core-philosophy--innovation)\n",
        "2. [System Architecture Overview](#system-architecture-overview)\n",
        "3. [Task Classification Taxonomy](#task-classification-taxonomy)\n",
        "4. [Flow Graph Data Structures](#flow-graph-data-structures)\n",
        "5. [Compilation Phase Algorithms](#compilation-phase-algorithms)\n",
        "6. [Runtime Execution Engine](#runtime-execution-engine)\n",
        "7. [Speculative Execution Framework](#speculative-execution-framework)\n",
        "8. [Adaptive Resource Allocation](#adaptive-resource-allocation)\n",
        "9. [Fault Tolerance & Self-Healing](#fault-tolerance--self-healing)\n",
        "10. [Backpressure & Flow Control](#backpressure--flow-control)\n",
        "11. [Observability & Metrics](#observability--metrics)\n",
        "12. [Pseudo Algorithm Specifications](#pseudo-algorithm-specifications)\n",
        "13. [Complexity Analysis](#complexity-analysis)\n",
        "14. [Deployment Topology](#deployment-topology)\n",
        "\n",
        "---\n",
        "\n",
        "# CORE PHILOSOPHY & INNOVATION\n",
        "\n",
        "\n",
        "=============================================================================\n",
        "INNOVATION THESIS: Beyond Static DAG Execution\n",
        "=============================================================================\n",
        "Current SOTA Limitations:\n",
        "- Airflow: Static DAG, no runtime adaptation, heavy scheduler overhead\n",
        "- Celery: No native dependency graph, manual chaining required\n",
        "- Temporal: Workflow-centric, not optimized for heterogeneous task graphs\n",
        "- Prefect: Dynamic but lacks speculative execution and criticality analysis\n",
        "\n",
        "ADAGE Innovation Pillars:\n",
        "1. CRITICALITY-WEIGHTED PRIORITY SCHEDULING (CWPS)\n",
        "   - Tasks scored by downstream impact, not just dependency order\n",
        "   - Critical path tasks preemptively allocated premium resources\n",
        "\n",
        "2. SPECULATIVE DEPENDENCY RESOLUTION (SDR)\n",
        "   - Begin dependent tasks before dependencies complete using predicted outputs\n",
        "   - Rollback mechanism if prediction incorrect\n",
        "\n",
        "3. ADAPTIVE TOPOLOGY REORDERING (ATR)\n",
        "   - Runtime DAG restructuring based on observed execution characteristics\n",
        "   - Hot path optimization through execution history analysis\n",
        "\n",
        "4. PREDICTIVE RESOURCE ALLOCATION (PRA)\n",
        "   - ML-driven resource prediction based on task signatures\n",
        "   - Elastic worker pool with task-type affinity\n",
        "\n",
        "5. CHECKPOINT-DELTA PROPAGATION (CDP)\n",
        "   - Incremental state transfer between dependent tasks\n",
        "   - Reduce serialization overhead through delta encoding\n",
        "=============================================================================\n",
        "\n",
        "\n",
        "## Design Principles\n",
        "\n",
        "<!--\n",
        "PRINCIPLE 1: Zero-Wait Maximization\n",
        "- No task should wait for resources if runnable\n",
        "- Speculative execution fills pipeline bubbles\n",
        "\n",
        "PRINCIPLE 2: Failure Isolation\n",
        "- Task failure isolated to minimal blast radius\n",
        "- Dependent tasks notified via poison pill, not cascade\n",
        "\n",
        "PRINCIPLE 3: Resource Elasticity\n",
        "- Worker pools scale with queue depth and task criticality\n",
        "- Heterogeneous workers match task requirements\n",
        "\n",
        "PRINCIPLE 4: Observability by Default\n",
        "- Every state transition emits structured event\n",
        "- Distributed tracing spans entire task graph execution\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# SYSTEM ARCHITECTURE OVERVIEW\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "MULTI-LAYER ARCHITECTURE\n",
        "=============================================================================\n",
        "\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                         CLIENT LAYER                                     │\n",
        "│  [Task Definitions] [Dependency Declarations] [Execution Policies]      │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "                                    │\n",
        "                                    ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                      COMPILATION LAYER                                   │\n",
        "│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐   │\n",
        "│  │   PARSER     │ │  OPTIMIZER   │ │   ANALYZER   │ │  SCHEDULER   │   │\n",
        "│  │              │ │              │ │              │ │   GENERATOR  │   │\n",
        "│  │ - Validate   │ │ - Fusion     │ │ - Critical   │ │              │   │\n",
        "│  │ - Normalize  │ │ - Hoisting   │ │   Path       │ │ - Priority   │   │\n",
        "│  │ - Type Check │ │ - Parallelize│ │ - Resource   │ │   Queues     │   │\n",
        "│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘   │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "                                    │\n",
        "                                    ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                     ORCHESTRATION LAYER                                  │\n",
        "│  ┌─────────────────────────────────────────────────────────────────┐   │\n",
        "│  │                    EXECUTION COORDINATOR                         │   │\n",
        "│  │  - State Machine Manager    - Speculative Executor               │   │\n",
        "│  │  - Checkpoint Controller    - Rollback Handler                   │   │\n",
        "│  └─────────────────────────────────────────────────────────────────┘   │\n",
        "│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐   │\n",
        "│  │   DISPATCH   │ │   RESOURCE   │ │   RESULT     │ │   FAILURE    │   │\n",
        "│  │   QUEUE      │ │   ALLOCATOR  │ │   AGGREGATOR │ │   HANDLER    │   │\n",
        "│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘   │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "                                    │\n",
        "                                    ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                       EXECUTION LAYER                                    │\n",
        "│  ┌────────────────────────────────────────────────────────────────┐    │\n",
        "│  │                    WORKER POOL MANAGER                          │    │\n",
        "│  └────────────────────────────────────────────────────────────────┘    │\n",
        "│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐     │\n",
        "│  │ FAST     │ │ STANDARD │ │ HEAVY    │ │ GPU      │ │ MEMORY   │     │\n",
        "│  │ WORKER   │ │ WORKER   │ │ WORKER   │ │ WORKER   │ │ WORKER   │     │\n",
        "│  │ POOL     │ │ POOL     │ │ POOL     │ │ POOL     │ │ POOL     │     │\n",
        "│  │          │ │          │ │          │ │          │ │          │     │\n",
        "│  │ <10ms    │ │ 10-500ms │ │ >500ms   │ │ GPU Bound│ │ RAM >4GB │     │\n",
        "│  └──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘     │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "                                    │\n",
        "                                    ▼\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                     PERSISTENCE LAYER                                    │\n",
        "│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐   │\n",
        "│  │   STATE      │ │   RESULT     │ │   CHECKPOINT │ │   DEAD       │   │\n",
        "│  │   STORE      │ │   CACHE      │ │   STORE      │ │   LETTER Q   │   │\n",
        "│  │   (Redis)    │ │   (Redis)    │ │   (S3/Minio) │ │   (Kafka)    │   │\n",
        "│  └──────────────┘ └──────────────┘ └──────────────┘ └──────────────┘   │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "=============================================================================\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# TASK CLASSIFICATION TAXONOMY\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "TASK CLASSIFICATION MATRIX\n",
        "=============================================================================\n",
        "Every task T_i classified along 4 orthogonal dimensions:\n",
        "\n",
        "DIMENSION 1: EXECUTION WEIGHT\n",
        "┌────────────────┬───────────────┬─────────────────────────────────────┐\n",
        "│ Classification │ Latency Range │ Resource Characteristics            │\n",
        "├────────────────┼───────────────┼─────────────────────────────────────┤\n",
        "│ NANO           │ < 1ms         │ In-memory, no I/O, pure computation │\n",
        "│ MICRO          │ 1ms - 10ms    │ Cache hits, simple DB lookups       │\n",
        "│ LIGHT          │ 10ms - 100ms  │ Single DB query, API call           │\n",
        "│ MEDIUM         │ 100ms - 1s    │ Multiple queries, file processing   │\n",
        "│ HEAVY          │ 1s - 60s      │ Large data, ML inference            │\n",
        "│ BATCH          │ > 60s         │ ETL, report generation              │\n",
        "└────────────────┴───────────────┴─────────────────────────────────────┘\n",
        "\n",
        "DIMENSION 2: DEPENDENCY PATTERN\n",
        "┌────────────────┬─────────────────────────────────────────────────────┐\n",
        "│ Pattern        │ Description                                         │\n",
        "├────────────────┼─────────────────────────────────────────────────────┤\n",
        "│ INDEPENDENT    │ No dependencies, can execute immediately            │\n",
        "│ SEQUENTIAL     │ Single predecessor must complete                    │\n",
        "│ FAN-IN         │ Multiple predecessors must all complete (AND-join)  │\n",
        "│ FAN-OUT        │ Single task triggers multiple successors            │\n",
        "│ CONDITIONAL    │ Dependency satisfied based on predecessor result    │\n",
        "│ DYNAMIC        │ Dependencies determined at runtime                  │\n",
        "└────────────────┴─────────────────────────────────────────────────────┘\n",
        "\n",
        "DIMENSION 3: IDEMPOTENCY CLASS\n",
        "┌────────────────┬─────────────────────────────────────────────────────┐\n",
        "│ Class          │ Retry Semantics                                     │\n",
        "├────────────────┼─────────────────────────────────────────────────────┤\n",
        "│ PURE           │ Safe to retry unlimited times, no side effects      │\n",
        "│ IDEMPOTENT     │ Safe to retry, same result guaranteed               │\n",
        "│ AT-MOST-ONCE   │ Execute maximum once, failure = skip                │\n",
        "│ AT-LEAST-ONCE  │ Must complete, duplicates acceptable                │\n",
        "│ EXACTLY-ONCE   │ Requires distributed transaction / outbox pattern   │\n",
        "└────────────────┴─────────────────────────────────────────────────────┘\n",
        "\n",
        "DIMENSION 4: CRITICALITY LEVEL\n",
        "┌────────────────┬─────────────────────────────────────────────────────┐\n",
        "│ Level          │ Impact Assessment                                   │\n",
        "├────────────────┼─────────────────────────────────────────────────────┤\n",
        "│ CRITICAL       │ On critical path, delays cascade to completion      │\n",
        "│ HIGH           │ Significant downstream impact, many dependents      │\n",
        "│ MEDIUM         │ Moderate impact, parallel alternatives exist        │\n",
        "│ LOW            │ Minimal impact, optional optimization task          │\n",
        "│ BACKGROUND     │ No immediate impact, can be deferred indefinitely   │\n",
        "└────────────────┴─────────────────────────────────────────────────────┘\n",
        "\n",
        "COMPOSITE TASK SIGNATURE:\n",
        "TaskSignature = (Weight, DependencyPattern, IdempotencyClass, Criticality)\n",
        "\n",
        "Example: T_payment = (LIGHT, SEQUENTIAL, EXACTLY-ONCE, CRITICAL)\n",
        "Example: T_thumbnail = (HEAVY, FAN-OUT, PURE, LOW)\n",
        "=============================================================================\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# FLOW GRAPH DATA STRUCTURES\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "CORE DATA STRUCTURES\n",
        "=============================================================================\n",
        "\n",
        "STRUCTURE 1: TASK NODE\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "TaskNode {\n",
        "    id:                 UUID                    // Unique task identifier\n",
        "    name:               String                  // Human-readable name\n",
        "    signature:          TaskSignature           // Classification tuple\n",
        "    \n",
        "    // Execution Metadata\n",
        "    handler:            FunctionPointer         // Actual task implementation\n",
        "    timeout:            Duration                // Maximum execution time\n",
        "    retry_policy:       RetryPolicy             // Backoff configuration\n",
        "    \n",
        "    // Resource Requirements\n",
        "    cpu_units:          Float                   // CPU cores required (0.1 - 16)\n",
        "    memory_mb:          Integer                 // Memory requirement\n",
        "    gpu_required:       Boolean                 // GPU acceleration needed\n",
        "    \n",
        "    // Runtime State\n",
        "    state:              TaskState               // Current execution state\n",
        "    attempts:           Integer                 // Retry count\n",
        "    checkpoints:        List<Checkpoint>        // Recovery points\n",
        "    \n",
        "    // Dependency Tracking\n",
        "    predecessors:       Set<TaskNode>           // Upstream dependencies\n",
        "    successors:         Set<TaskNode>           // Downstream dependents\n",
        "    input_mapping:      Map<TaskNode, Selector> // Output-to-input mapping\n",
        "    \n",
        "    // Metrics\n",
        "    estimated_duration: Duration                // Predicted execution time\n",
        "    actual_duration:    Duration                // Observed execution time\n",
        "    criticality_score:  Float                   // Computed priority score\n",
        "}\n",
        "\n",
        "STRUCTURE 2: EXECUTION GRAPH\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "ExecutionGraph {\n",
        "    id:                 UUID                    // Graph instance ID\n",
        "    nodes:              Map<UUID, TaskNode>     // All tasks in graph\n",
        "    edges:              List<Edge>              // Dependency edges\n",
        "    \n",
        "    // Computed Properties\n",
        "    topological_order:  List<UUID>              // Valid execution order\n",
        "    critical_path:      List<UUID>              // Longest duration path\n",
        "    parallel_stages:    List<Set<UUID>>         // Parallelizable groups\n",
        "    \n",
        "    // Optimization Metadata\n",
        "    fusion_groups:      List<FusionGroup>       // Merged task clusters\n",
        "    speculative_hints:  Map<UUID, Prediction>   // Output predictions\n",
        "    \n",
        "    // Execution State\n",
        "    status:             GraphStatus             // PENDING|RUNNING|COMPLETE|FAILED\n",
        "    start_time:         Timestamp               // Execution start\n",
        "    completion_time:    Timestamp               // Execution end\n",
        "}\n",
        "\n",
        "STRUCTURE 3: EDGE (DEPENDENCY)\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "Edge {\n",
        "    source:             UUID                    // Predecessor task\n",
        "    target:             UUID                    // Successor task\n",
        "    type:               EdgeType                // DATA|CONTROL|TEMPORAL\n",
        "    \n",
        "    // Data Flow\n",
        "    selector:           OutputSelector          // Which output field to pass\n",
        "    transformer:        TransformFunction       // Optional data transformation\n",
        "    \n",
        "    // Conditional Execution\n",
        "    condition:          PredicateFunction       // When to activate edge\n",
        "    \n",
        "    // Edge Weights (for optimization)\n",
        "    data_size_estimate: Bytes                   // Expected data transfer size\n",
        "    latency_overhead:   Duration                // Serialization/transfer time\n",
        "}\n",
        "\n",
        "STRUCTURE 4: TASK STATE MACHINE\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "TaskState Enum:\n",
        "    PENDING         → Initial state, dependencies not met\n",
        "    READY           → Dependencies satisfied, awaiting dispatch\n",
        "    SPECULATIVE     → Started speculatively before dependencies complete\n",
        "    DISPATCHED      → Assigned to worker, in queue\n",
        "    RUNNING         → Actively executing on worker\n",
        "    CHECKPOINTED    → Paused with state saved\n",
        "    SUCCEEDED       → Completed successfully\n",
        "    FAILED          → Failed, may retry\n",
        "    DEAD_LETTERED   → Permanently failed, moved to DLQ\n",
        "    ROLLED_BACK     → Speculative execution invalidated\n",
        "    SKIPPED         → Bypassed due to conditional logic\n",
        "    CANCELLED       → Externally terminated\n",
        "\n",
        "State Transition Graph:\n",
        "    PENDING ──[deps_met]──→ READY\n",
        "    PENDING ──[speculate]──→ SPECULATIVE\n",
        "    READY ──[dispatch]──→ DISPATCHED\n",
        "    DISPATCHED ──[worker_ack]──→ RUNNING\n",
        "    RUNNING ──[success]──→ SUCCEEDED\n",
        "    RUNNING ──[failure]──→ FAILED\n",
        "    RUNNING ──[checkpoint]──→ CHECKPOINTED\n",
        "    FAILED ──[retry]──→ DISPATCHED\n",
        "    FAILED ──[max_retries]──→ DEAD_LETTERED\n",
        "    SPECULATIVE ──[validated]──→ SUCCEEDED\n",
        "    SPECULATIVE ──[invalidated]──→ ROLLED_BACK\n",
        "    ROLLED_BACK ──[re-enqueue]──→ READY\n",
        "\n",
        "STRUCTURE 5: PRIORITY QUEUE ENTRY\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "QueueEntry {\n",
        "    task_id:            UUID\n",
        "    priority_score:     Float                   // Higher = more urgent\n",
        "    enqueue_time:       Timestamp\n",
        "    deadline:           Timestamp               // Optional hard deadline\n",
        "    affinity_hints:     List<WorkerType>        // Preferred worker pools\n",
        "}\n",
        "\n",
        "Priority Score Computation:\n",
        "    score = (criticality_weight * criticality_score) +\n",
        "            (deadline_weight * deadline_urgency) +\n",
        "            (wait_weight * time_in_queue) +\n",
        "            (dependency_weight * blocked_task_count) -\n",
        "            (speculation_penalty if speculative)\n",
        "\n",
        "=============================================================================\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# COMPILATION PHASE ALGORITHMS\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "PHASE 1: GRAPH CONSTRUCTION & VALIDATION\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: BuildExecutionGraph\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  task_definitions: List<TaskDefinition>\n",
        "        dependency_declarations: List<DependencyDeclaration>\n",
        "OUTPUT: validated_graph: ExecutionGraph\n",
        "\n",
        "PROCEDURE:\n",
        "    1. INITIALIZATION\n",
        "       graph ← new ExecutionGraph()\n",
        "       node_map ← empty Map<String, TaskNode>\n",
        "    \n",
        "    2. NODE CREATION\n",
        "       FOR EACH task_def IN task_definitions:\n",
        "           node ← CreateTaskNode(task_def)\n",
        "           node.signature ← ClassifyTask(task_def)\n",
        "           node_map[task_def.name] ← node\n",
        "           graph.nodes.add(node)\n",
        "    \n",
        "    3. EDGE CONSTRUCTION\n",
        "       FOR EACH dep IN dependency_declarations:\n",
        "           source ← node_map[dep.predecessor]\n",
        "           target ← node_map[dep.successor]\n",
        "           \n",
        "           VALIDATE source EXISTS AND target EXISTS\n",
        "           \n",
        "           edge ← CreateEdge(source, target, dep)\n",
        "           graph.edges.add(edge)\n",
        "           \n",
        "           source.successors.add(target)\n",
        "           target.predecessors.add(source)\n",
        "    \n",
        "    4. CYCLE DETECTION (Tarjan's Algorithm)\n",
        "       sccs ← TarjanSCC(graph)\n",
        "       IF any scc.size > 1:\n",
        "           RAISE CyclicDependencyError(scc)\n",
        "    \n",
        "    5. ORPHAN DETECTION\n",
        "       FOR EACH node IN graph.nodes:\n",
        "           IF node.predecessors.empty AND node.successors.empty:\n",
        "               WARN \"Isolated task detected: \" + node.name\n",
        "    \n",
        "    6. TYPE COMPATIBILITY VALIDATION\n",
        "       FOR EACH edge IN graph.edges:\n",
        "           source_output_type ← edge.source.output_schema\n",
        "           target_input_type ← edge.target.input_schema[edge.selector]\n",
        "           IF NOT compatible(source_output_type, target_input_type):\n",
        "               RAISE TypeMismatchError(edge)\n",
        "    \n",
        "    RETURN graph\n",
        "\n",
        "COMPLEXITY: O(V + E) where V = tasks, E = dependencies\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "=============================================================================\n",
        "PHASE 2: TOPOLOGICAL ORDERING WITH PRIORITY LAYERS\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: ComputeExecutionOrder\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph: ExecutionGraph\n",
        "OUTPUT: ordered_stages: List<Set<TaskNode>>\n",
        "\n",
        "PROCEDURE:\n",
        "    1. COMPUTE IN-DEGREES\n",
        "       in_degree ← Map<TaskNode, Integer>\n",
        "       FOR EACH node IN graph.nodes:\n",
        "           in_degree[node] ← node.predecessors.size\n",
        "    \n",
        "    2. INITIALIZE READY SET\n",
        "       ready ← Set containing all nodes where in_degree[node] = 0\n",
        "       ordered_stages ← empty List\n",
        "       stage_index ← 0\n",
        "    \n",
        "    3. WAVEFRONT PROPAGATION (Kahn's Algorithm Extended)\n",
        "       WHILE ready NOT EMPTY:\n",
        "           current_stage ← copy of ready\n",
        "           ready ← empty Set\n",
        "           \n",
        "           // Sort within stage by criticality\n",
        "           current_stage.sort_descending(by: node.criticality_score)\n",
        "           ordered_stages.append(current_stage)\n",
        "           \n",
        "           FOR EACH node IN current_stage:\n",
        "               FOR EACH successor IN node.successors:\n",
        "                   in_degree[successor] ← in_degree[successor] - 1\n",
        "                   IF in_degree[successor] = 0:\n",
        "                       ready.add(successor)\n",
        "           \n",
        "           stage_index ← stage_index + 1\n",
        "    \n",
        "    4. VALIDATE COMPLETE ORDERING\n",
        "       total_ordered ← sum of stage sizes\n",
        "       IF total_ordered ≠ graph.nodes.size:\n",
        "           RAISE GraphNotFullyOrderableError()\n",
        "    \n",
        "    graph.parallel_stages ← ordered_stages\n",
        "    RETURN ordered_stages\n",
        "\n",
        "COMPLEXITY: O(V + E)\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "=============================================================================\n",
        "PHASE 3: CRITICAL PATH ANALYSIS\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: ComputeCriticalPath\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph: ExecutionGraph\n",
        "OUTPUT: critical_path: List<TaskNode>\n",
        "        criticality_scores: Map<TaskNode, Float>\n",
        "\n",
        "PROCEDURE:\n",
        "    1. FORWARD PASS - Earliest Start Time (EST)\n",
        "       est ← Map<TaskNode, Duration>\n",
        "       \n",
        "       FOR EACH node IN graph.topological_order:\n",
        "           IF node.predecessors.empty:\n",
        "               est[node] ← 0\n",
        "           ELSE:\n",
        "               est[node] ← MAX(\n",
        "                   est[pred] + pred.estimated_duration\n",
        "                   FOR pred IN node.predecessors\n",
        "               )\n",
        "    \n",
        "    2. COMPUTE TOTAL DURATION\n",
        "       terminal_nodes ← nodes with no successors\n",
        "       total_duration ← MAX(est[n] + n.estimated_duration FOR n IN terminal_nodes)\n",
        "    \n",
        "    3. BACKWARD PASS - Latest Start Time (LST)\n",
        "       lst ← Map<TaskNode, Duration>\n",
        "       \n",
        "       FOR EACH node IN REVERSE(graph.topological_order):\n",
        "           IF node.successors.empty:\n",
        "               lst[node] ← total_duration - node.estimated_duration\n",
        "           ELSE:\n",
        "               lst[node] ← MIN(lst[succ] FOR succ IN node.successors)\n",
        "                           - node.estimated_duration\n",
        "    \n",
        "    4. COMPUTE SLACK (Float)\n",
        "       slack ← Map<TaskNode, Duration>\n",
        "       FOR EACH node IN graph.nodes:\n",
        "           slack[node] ← lst[node] - est[node]\n",
        "    \n",
        "    5. IDENTIFY CRITICAL PATH (slack = 0)\n",
        "       critical_nodes ← nodes WHERE slack[node] = 0\n",
        "       critical_path ← order critical_nodes by est ascending\n",
        "    \n",
        "    6. COMPUTE CRITICALITY SCORES\n",
        "       max_downstream ← MAX(successor_count(n) FOR n IN graph.nodes)\n",
        "       \n",
        "       FOR EACH node IN graph.nodes:\n",
        "           // Normalized score 0.0 - 1.0\n",
        "           slack_factor ← 1.0 - (slack[node] / total_duration)\n",
        "           downstream_factor ← downstream_count(node) / max_downstream\n",
        "           duration_factor ← node.estimated_duration / total_duration\n",
        "           \n",
        "           criticality_scores[node] ←\n",
        "               0.5 * slack_factor +\n",
        "               0.3 * downstream_factor +\n",
        "               0.2 * duration_factor\n",
        "    \n",
        "    graph.critical_path ← critical_path\n",
        "    RETURN critical_path, criticality_scores\n",
        "\n",
        "COMPLEXITY: O(V + E)\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "=============================================================================\n",
        "PHASE 4: TASK FUSION OPTIMIZATION\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: FuseCompatibleTasks\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph: ExecutionGraph\n",
        "OUTPUT: optimized_graph: ExecutionGraph with fusion groups\n",
        "\n",
        "PROCEDURE:\n",
        "    1. IDENTIFY FUSION CANDIDATES\n",
        "       // Tasks that can be merged into single execution unit\n",
        "       \n",
        "       fusion_candidates ← empty List<Pair<TaskNode, TaskNode>>\n",
        "       \n",
        "       FOR EACH edge IN graph.edges:\n",
        "           source ← edge.source\n",
        "           target ← edge.target\n",
        "           \n",
        "           // Fusion criteria\n",
        "           can_fuse ← ALL OF:\n",
        "               - source.successors.size = 1                    // Single output\n",
        "               - target.predecessors.size = 1                  // Single input\n",
        "               - source.weight + target.weight ≤ LIGHT         // Combined still fast\n",
        "               - source.worker_affinity = target.worker_affinity\n",
        "               - source.idempotency_class = target.idempotency_class\n",
        "               - edge.data_size_estimate < FUSION_DATA_THRESHOLD\n",
        "               - NOT source.checkpoint_required\n",
        "               - NOT target.checkpoint_required\n",
        "           \n",
        "           IF can_fuse:\n",
        "               fusion_candidates.append((source, target))\n",
        "    \n",
        "    2. GREEDY FUSION (avoid conflicts)\n",
        "       fused ← empty Set<TaskNode>\n",
        "       fusion_groups ← empty List<FusionGroup>\n",
        "       \n",
        "       FOR EACH (source, target) IN fusion_candidates:\n",
        "           IF source NOT IN fused AND target NOT IN fused:\n",
        "               group ← new FusionGroup(source, target)\n",
        "               fusion_groups.append(group)\n",
        "               fused.add(source)\n",
        "               fused.add(target)\n",
        "    \n",
        "    3. EXTEND FUSION CHAINS\n",
        "       // Merge consecutive fuseable tasks into longer chains\n",
        "       \n",
        "       changed ← true\n",
        "       WHILE changed:\n",
        "           changed ← false\n",
        "           FOR EACH group IN fusion_groups:\n",
        "               last_task ← group.tasks.last()\n",
        "               IF last_task.successors.size = 1:\n",
        "                   next_task ← last_task.successors.first()\n",
        "                   IF can_fuse(last_task, next_task) AND next_task NOT IN fused:\n",
        "                       group.tasks.append(next_task)\n",
        "                       fused.add(next_task)\n",
        "                       changed ← true\n",
        "    \n",
        "    4. CREATE FUSED NODES\n",
        "       FOR EACH group IN fusion_groups:\n",
        "           fused_node ← MergeTasks(group.tasks)\n",
        "           fused_node.estimated_duration ← SUM(t.estimated_duration FOR t IN group.tasks)\n",
        "           fused_node.handler ← CreatePipeline(group.tasks)\n",
        "           \n",
        "           // Update graph edges\n",
        "           ReplaceInGraph(graph, group.tasks, fused_node)\n",
        "    \n",
        "    RETURN graph\n",
        "\n",
        "BENEFIT: Reduces scheduling overhead, eliminates serialization between fused tasks\n",
        "COMPLEXITY: O(E) for candidate identification, O(V) for fusion\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "=============================================================================\n",
        "PHASE 5: SPECULATION CANDIDATE IDENTIFICATION\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: IdentifySpeculativeTasks\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph: ExecutionGraph\n",
        "        historical_data: ExecutionHistory\n",
        "OUTPUT: speculation_plan: Map<TaskNode, SpeculationConfig>\n",
        "\n",
        "PROCEDURE:\n",
        "    1. ANALYZE HISTORICAL PATTERNS\n",
        "       FOR EACH task IN graph.nodes:\n",
        "           task.success_rate ← ComputeSuccessRate(historical_data, task)\n",
        "           task.output_predictability ← ComputeOutputVariance(historical_data, task)\n",
        "           task.avg_duration ← ComputeAvgDuration(historical_data, task)\n",
        "    \n",
        "    2. IDENTIFY SPECULATION OPPORTUNITIES\n",
        "       speculation_plan ← empty Map\n",
        "       \n",
        "       FOR EACH task IN graph.nodes WHERE task.predecessors NOT EMPTY:\n",
        "           // Score speculative potential\n",
        "           pred_durations ← [p.avg_duration FOR p IN task.predecessors]\n",
        "           max_pred_duration ← MAX(pred_durations)\n",
        "           own_duration ← task.avg_duration\n",
        "           \n",
        "           // Speculation worthwhile if predecessor takes long\n",
        "           // and own task is fast or on critical path\n",
        "           \n",
        "           speculation_score ←\n",
        "               (max_pred_duration / own_duration) *    // Wait ratio\n",
        "               task.criticality_score *                  // Importance\n",
        "               MIN(p.output_predictability FOR p IN task.predecessors)\n",
        "           \n",
        "           IF speculation_score > SPECULATION_THRESHOLD:\n",
        "               config ← new SpeculationConfig()\n",
        "               config.trigger_point ← 0.8 * max_pred_duration  // Start at 80% expected\n",
        "               config.prediction_model ← SelectPredictionModel(task.predecessors)\n",
        "               config.rollback_cost ← EstimateRollbackCost(task)\n",
        "               speculation_plan[task] ← config\n",
        "    \n",
        "    3. VALIDATE SPECULATION SAFETY\n",
        "       FOR EACH (task, config) IN speculation_plan:\n",
        "           IF task.idempotency_class NOT IN [PURE, IDEMPOTENT]:\n",
        "               // Non-idempotent tasks need special handling\n",
        "               config.requires_shadow_execution ← true\n",
        "               config.commit_on_validation ← true\n",
        "    \n",
        "    graph.speculative_hints ← speculation_plan\n",
        "    RETURN speculation_plan\n",
        "\n",
        "COMPLEXITY: O(V) with historical data lookup\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# RUNTIME EXECUTION ENGINE\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "CORE EXECUTION LOOP\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: ExecuteGraph\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph: ExecutionGraph\n",
        "        input_data: InitialInputs\n",
        "OUTPUT: execution_result: GraphExecutionResult\n",
        "\n",
        "PROCEDURE:\n",
        "    1. INITIALIZE EXECUTION CONTEXT\n",
        "       context ← new ExecutionContext()\n",
        "       context.graph ← graph\n",
        "       context.results ← empty Map<TaskNode, TaskResult>\n",
        "       context.states ← Map(all nodes → PENDING)\n",
        "       context.start_time ← now()\n",
        "       \n",
        "       // Initialize priority queues\n",
        "       ready_queue ← new PriorityQueue(by: criticality_score DESC)\n",
        "       speculative_queue ← new PriorityQueue(by: speculation_score DESC)\n",
        "       \n",
        "       // Event channels\n",
        "       completion_channel ← new Channel<TaskCompletion>()\n",
        "       failure_channel ← new Channel<TaskFailure>()\n",
        "    \n",
        "    2. SEED INITIAL TASKS\n",
        "       FOR EACH node IN graph.nodes WHERE node.predecessors.empty:\n",
        "           context.states[node] ← READY\n",
        "           ready_queue.enqueue(CreateQueueEntry(node))\n",
        "           EmitEvent(TaskReady, node)\n",
        "    \n",
        "    3. MAIN EXECUTION LOOP\n",
        "       pending_count ← graph.nodes.size\n",
        "       active_tasks ← empty Set<TaskNode>\n",
        "       \n",
        "       WHILE pending_count > 0:\n",
        "           \n",
        "           // 3A. DISPATCH READY TASKS\n",
        "           WHILE ready_queue.not_empty AND ResourcesAvailable():\n",
        "               entry ← ready_queue.dequeue()\n",
        "               task ← graph.nodes[entry.task_id]\n",
        "               \n",
        "               IF context.states[task] ≠ READY:\n",
        "                   CONTINUE  // State changed, skip\n",
        "               \n",
        "               worker ← AllocateWorker(task)\n",
        "               DispatchToWorker(worker, task, context.results)\n",
        "               context.states[task] ← DISPATCHED\n",
        "               active_tasks.add(task)\n",
        "               EmitEvent(TaskDispatched, task, worker)\n",
        "           \n",
        "           // 3B. TRIGGER SPECULATIVE EXECUTION\n",
        "           IF speculation_enabled:\n",
        "               CheckAndTriggerSpeculation(context, speculative_queue)\n",
        "           \n",
        "           // 3C. WAIT FOR COMPLETION EVENTS\n",
        "           SELECT:\n",
        "               CASE completion ← completion_channel.receive():\n",
        "                   HandleTaskCompletion(context, completion, ready_queue)\n",
        "                   pending_count ← pending_count - 1\n",
        "                   active_tasks.remove(completion.task)\n",
        "               \n",
        "               CASE failure ← failure_channel.receive():\n",
        "                   HandleTaskFailure(context, failure, ready_queue)\n",
        "                   // pending_count adjusted in handler\n",
        "                   active_tasks.remove(failure.task)\n",
        "               \n",
        "               CASE TIMEOUT after HEARTBEAT_INTERVAL:\n",
        "                   CheckStaleTasks(active_tasks)\n",
        "                   AdjustResourceAllocation(context)\n",
        "    \n",
        "    4. FINALIZE RESULTS\n",
        "       execution_result ← new GraphExecutionResult()\n",
        "       execution_result.status ← DetermineOverallStatus(context)\n",
        "       execution_result.outputs ← CollectTerminalOutputs(context)\n",
        "       execution_result.duration ← now() - context.start_time\n",
        "       execution_result.metrics ← CollectMetrics(context)\n",
        "       \n",
        "       RETURN execution_result\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: HandleTaskCompletion\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  context: ExecutionContext\n",
        "        completion: TaskCompletion\n",
        "        ready_queue: PriorityQueue\n",
        "\n",
        "PROCEDURE:\n",
        "    task ← completion.task\n",
        "    result ← completion.result\n",
        "    \n",
        "    1. STORE RESULT\n",
        "       context.results[task] ← result\n",
        "       context.states[task] ← SUCCEEDED\n",
        "       EmitEvent(TaskCompleted, task, result.duration)\n",
        "    \n",
        "    2. VALIDATE SPECULATIVE DEPENDENTS\n",
        "       FOR EACH speculative_task IN GetSpeculativeDependents(task):\n",
        "           actual_input ← result.output\n",
        "           predicted_input ← speculative_task.predicted_input\n",
        "           \n",
        "           IF InputsMatch(actual_input, predicted_input):\n",
        "               // Speculation successful, validate execution\n",
        "               context.states[speculative_task] ← SUCCEEDED\n",
        "               EmitEvent(SpeculationValidated, speculative_task)\n",
        "           ELSE:\n",
        "               // Speculation failed, rollback and re-execute\n",
        "               RollbackTask(speculative_task, context)\n",
        "               context.states[speculative_task] ← READY\n",
        "               ready_queue.enqueue(CreateQueueEntry(speculative_task))\n",
        "               EmitEvent(SpeculationRolledBack, speculative_task)\n",
        "    \n",
        "    3. ACTIVATE SUCCESSORS\n",
        "       FOR EACH successor IN task.successors:\n",
        "           IF AllPredecessorsSatisfied(successor, context):\n",
        "               IF context.states[successor] = PENDING:\n",
        "                   context.states[successor] ← READY\n",
        "                   ready_queue.enqueue(CreateQueueEntry(successor))\n",
        "                   EmitEvent(TaskReady, successor)\n",
        "               ELIF context.states[successor] = SPECULATIVE:\n",
        "                   // Already running speculatively, will be validated\n",
        "                   PASS\n",
        "    \n",
        "    4. CACHE RESULT (if configured)\n",
        "       IF task.cacheable:\n",
        "           cache_key ← ComputeCacheKey(task, task.inputs)\n",
        "           ResultCache.store(cache_key, result, task.cache_ttl)\n",
        "    \n",
        "    5. UPDATE METRICS\n",
        "       UpdateDurationHistogram(task.name, result.duration)\n",
        "       UpdateResourceUtilization(result.resource_usage)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: HandleTaskFailure\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  context: ExecutionContext\n",
        "        failure: TaskFailure\n",
        "        ready_queue: PriorityQueue\n",
        "\n",
        "PROCEDURE:\n",
        "    task ← failure.task\n",
        "    error ← failure.error\n",
        "    attempt ← context.attempts[task]\n",
        "    \n",
        "    1. DETERMINE FAILURE ACTION\n",
        "       retry_policy ← task.retry_policy\n",
        "       \n",
        "       action ← CASE error.type OF:\n",
        "           TRANSIENT_ERROR:\n",
        "               IF attempt < retry_policy.max_retries:\n",
        "                   RETRY_WITH_BACKOFF\n",
        "               ELSE:\n",
        "                   DEAD_LETTER\n",
        "           \n",
        "           RESOURCE_EXHAUSTED:\n",
        "               IF attempt < 2:\n",
        "                   RETRY_WITH_SCALED_RESOURCES\n",
        "               ELSE:\n",
        "                   DEAD_LETTER\n",
        "           \n",
        "           VALIDATION_ERROR:\n",
        "               DEAD_LETTER  // Don't retry bad input\n",
        "           \n",
        "           TIMEOUT:\n",
        "               IF attempt < retry_policy.max_retries:\n",
        "                   RETRY_WITH_EXTENDED_TIMEOUT\n",
        "               ELSE:\n",
        "                   DEAD_LETTER\n",
        "           \n",
        "           FATAL_ERROR:\n",
        "               DEAD_LETTER\n",
        "    \n",
        "    2. EXECUTE FAILURE ACTION\n",
        "       CASE action OF:\n",
        "           RETRY_WITH_BACKOFF:\n",
        "               delay ← ComputeExponentialBackoff(attempt, retry_policy)\n",
        "               context.attempts[task] ← attempt + 1\n",
        "               ScheduleDelayedEnqueue(task, delay, ready_queue)\n",
        "               context.states[task] ← PENDING\n",
        "               EmitEvent(TaskRetryScheduled, task, delay)\n",
        "           \n",
        "           RETRY_WITH_SCALED_RESOURCES:\n",
        "               task.cpu_units ← task.cpu_units * 1.5\n",
        "               task.memory_mb ← task.memory_mb * 1.5\n",
        "               context.attempts[task] ← attempt + 1\n",
        "               ready_queue.enqueue(CreateQueueEntry(task))\n",
        "               context.states[task] ← READY\n",
        "               EmitEvent(TaskRetryWithResources, task)\n",
        "           \n",
        "           DEAD_LETTER:\n",
        "               context.states[task] ← DEAD_LETTERED\n",
        "               DeadLetterQueue.enqueue(task, error, context)\n",
        "               PropagateFailureToSuccessors(task, context)\n",
        "               EmitEvent(TaskDeadLettered, task, error)\n",
        "    \n",
        "    3. PROPAGATE FAILURE (if not retrying)\n",
        "       IF action = DEAD_LETTER:\n",
        "           FOR EACH successor IN GetAllDownstreamTasks(task):\n",
        "               IF task.failure_mode = FAIL_FAST:\n",
        "                   context.states[successor] ← SKIPPED\n",
        "                   EmitEvent(TaskSkipped, successor, \"Upstream failed\")\n",
        "               ELIF task.failure_mode = CONTINUE:\n",
        "                   // Mark dependency as failed but allow task if other paths exist\n",
        "                   MarkDependencyFailed(successor, task)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# SPECULATIVE EXECUTION FRAMEWORK\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "SPECULATIVE EXECUTION ARCHITECTURE\n",
        "=============================================================================\n",
        "\n",
        "CONCEPT: Begin executing a task BEFORE its dependencies complete,\n",
        "         using predicted outputs. Validate or rollback upon completion.\n",
        "\n",
        "Benefits:\n",
        "- Reduces critical path latency by overlapping execution\n",
        "- Utilizes idle resources during long-running dependencies\n",
        "- Particularly effective for predictable predecessor outputs\n",
        "\n",
        "Risks:\n",
        "- Wasted computation if prediction incorrect\n",
        "- Resource contention with actual work\n",
        "- Complexity in rollback for non-idempotent tasks\n",
        "\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: SpeculativeExecutionController\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "BACKGROUND PROCESS running continuously during graph execution\n",
        "\n",
        "PROCEDURE:\n",
        "    LOOP:\n",
        "        SLEEP(SPECULATION_CHECK_INTERVAL)\n",
        "        \n",
        "        FOR EACH running_task IN GetRunningTasks():\n",
        "            progress ← EstimateProgress(running_task)\n",
        "            remaining ← EstimateRemaining(running_task)\n",
        "            \n",
        "            FOR EACH successor IN running_task.successors:\n",
        "                spec_config ← speculation_plan.get(successor)\n",
        "                \n",
        "                IF spec_config IS NULL:\n",
        "                    CONTINUE\n",
        "                \n",
        "                IF ShouldSpeculate(running_task, successor, progress, spec_config):\n",
        "                    TriggerSpeculativeExecution(successor, running_task)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: ShouldSpeculate\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  predecessor: TaskNode (running)\n",
        "        successor: TaskNode (pending)\n",
        "        predecessor_progress: Float (0.0 - 1.0)\n",
        "        spec_config: SpeculationConfig\n",
        "\n",
        "OUTPUT: Boolean\n",
        "\n",
        "PROCEDURE:\n",
        "    // Check preconditions\n",
        "    IF successor.state ≠ PENDING:\n",
        "        RETURN false\n",
        "    \n",
        "    IF NOT ResourcesAvailableForSpeculation():\n",
        "        RETURN false\n",
        "    \n",
        "    // Check if we're past the trigger point\n",
        "    IF predecessor_progress < spec_config.trigger_point:\n",
        "        RETURN false\n",
        "    \n",
        "    // Check if all other dependencies are satisfied\n",
        "    FOR EACH other_pred IN successor.predecessors:\n",
        "        IF other_pred ≠ predecessor AND other_pred.state ≠ SUCCEEDED:\n",
        "            RETURN false\n",
        "    \n",
        "    // Compute speculation ROI\n",
        "    expected_wait ← (1.0 - predecessor_progress) * predecessor.estimated_duration\n",
        "    successor_duration ← successor.estimated_duration\n",
        "    rollback_cost ← spec_config.rollback_cost\n",
        "    prediction_accuracy ← spec_config.prediction_model.accuracy\n",
        "    \n",
        "    // Expected value of speculation\n",
        "    expected_gain ← expected_wait * prediction_accuracy\n",
        "    expected_loss ← rollback_cost * (1.0 - prediction_accuracy)\n",
        "    \n",
        "    IF expected_gain > expected_loss * SPECULATION_RISK_FACTOR:\n",
        "        RETURN true\n",
        "    \n",
        "    RETURN false\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: TriggerSpeculativeExecution\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  task: TaskNode\n",
        "        pending_predecessor: TaskNode\n",
        "\n",
        "PROCEDURE:\n",
        "    1. GENERATE PREDICTED INPUT\n",
        "       prediction_model ← speculation_plan[task].prediction_model\n",
        "       \n",
        "       // Use historical data and partial predecessor results\n",
        "       predicted_output ← prediction_model.predict(\n",
        "           predecessor: pending_predecessor,\n",
        "           partial_state: GetPartialState(pending_predecessor),\n",
        "           historical: GetHistoricalOutputs(pending_predecessor)\n",
        "       )\n",
        "       \n",
        "       task.predicted_input ← predicted_output\n",
        "       task.speculation_source ← pending_predecessor\n",
        "    \n",
        "    2. PREPARE SPECULATIVE CONTEXT\n",
        "       spec_context ← new SpeculativeContext()\n",
        "       spec_context.original_state ← CaptureState(task)\n",
        "       spec_context.shadow_mode ← task.requires_shadow_execution\n",
        "       \n",
        "       IF spec_context.shadow_mode:\n",
        "           // Create isolated execution environment\n",
        "           spec_context.sandbox ← CreateSandbox(task)\n",
        "    \n",
        "    3. DISPATCH SPECULATIVE EXECUTION\n",
        "       context.states[task] ← SPECULATIVE\n",
        "       \n",
        "       worker ← AllocateWorker(task, priority: LOW)  // Lower priority than confirmed work\n",
        "       DispatchToWorker(worker, task, spec_context)\n",
        "       \n",
        "       EmitEvent(SpeculativeExecutionStarted, task, pending_predecessor)\n",
        "    \n",
        "    4. REGISTER VALIDATION CALLBACK\n",
        "       OnComplete(pending_predecessor, () => {\n",
        "           ValidateSpeculation(task, pending_predecessor.result)\n",
        "       })\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: ValidateSpeculation\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  speculative_task: TaskNode\n",
        "        actual_predecessor_output: Output\n",
        "\n",
        "PROCEDURE:\n",
        "    predicted_input ← speculative_task.predicted_input\n",
        "    \n",
        "    1. COMPARE INPUTS\n",
        "       match_result ← CompareInputs(predicted_input, actual_predecessor_output)\n",
        "       \n",
        "       CASE match_result OF:\n",
        "           EXACT_MATCH:\n",
        "               // Perfect prediction, commit results\n",
        "               CommitSpeculativeResult(speculative_task)\n",
        "               context.states[speculative_task] ← SUCCEEDED\n",
        "               EmitEvent(SpeculationValidated, speculative_task, \"exact\")\n",
        "           \n",
        "           SEMANTIC_MATCH:\n",
        "               // Output structurally same but values differ\n",
        "               // Check if differences affect computation\n",
        "               IF OutputDifferencesImmaterial(speculative_task, predicted_input, actual_input):\n",
        "                   CommitSpeculativeResult(speculative_task)\n",
        "                   context.states[speculative_task] ← SUCCEEDED\n",
        "                   EmitEvent(SpeculationValidated, speculative_task, \"semantic\")\n",
        "               ELSE:\n",
        "                   RollbackAndReexecute(speculative_task, actual_predecessor_output)\n",
        "           \n",
        "           MISMATCH:\n",
        "               RollbackAndReexecute(speculative_task, actual_predecessor_output)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: RollbackAndReexecute\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  task: TaskNode\n",
        "        correct_input: Input\n",
        "\n",
        "PROCEDURE:\n",
        "    1. CANCEL IN-PROGRESS EXECUTION\n",
        "       IF task.state = RUNNING:\n",
        "           CancelWorkerExecution(task)\n",
        "       \n",
        "       EmitEvent(SpeculationRolledBack, task)\n",
        "    \n",
        "    2. REVERT SIDE EFFECTS\n",
        "       IF task.has_side_effects:\n",
        "           spec_context ← GetSpeculativeContext(task)\n",
        "           \n",
        "           IF spec_context.shadow_mode:\n",
        "               // Discard sandbox, no cleanup needed\n",
        "               DestroySandbox(spec_context.sandbox)\n",
        "           ELSE:\n",
        "               // Execute compensation logic\n",
        "               ExecuteCompensation(task, spec_context.original_state)\n",
        "    \n",
        "    3. PREPARE CORRECT EXECUTION\n",
        "       task.predicted_input ← NULL\n",
        "       task.speculation_source ← NULL\n",
        "       task.inputs ← CollectActualInputs(task)\n",
        "       context.states[task] ← READY\n",
        "    \n",
        "    4. RE-ENQUEUE WITH PRIORITY BOOST\n",
        "       // Boosted priority since we wasted time\n",
        "       entry ← CreateQueueEntry(task)\n",
        "       entry.priority_score ← entry.priority_score * ROLLBACK_PRIORITY_BOOST\n",
        "       ready_queue.enqueue(entry)\n",
        "    \n",
        "    5. UPDATE PREDICTION MODEL\n",
        "       // Feedback loop to improve future predictions\n",
        "       prediction_model ← speculation_plan[task].prediction_model\n",
        "       prediction_model.recordFailure(\n",
        "           predicted: task.predicted_input,\n",
        "           actual: correct_input\n",
        "       )\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# ADAPTIVE RESOURCE ALLOCATION\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "DYNAMIC WORKER POOL MANAGEMENT\n",
        "=============================================================================\n",
        "\n",
        "ARCHITECTURE: Heterogeneous worker pools with task affinity\n",
        "\n",
        "WORKER POOL TYPES:\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│  POOL TYPE      │ CAPACITY │ CHARACTERISTICS                           │\n",
        "├─────────────────────────────────────────────────────────────────────────┤\n",
        "│  NANO_POOL      │ 100+     │ In-process, <1ms tasks, zero overhead    │\n",
        "│  MICRO_POOL     │ 50       │ Thread-based, 1-10ms, shared memory      │\n",
        "│  STANDARD_POOL  │ 20       │ Process-based, 10ms-1s, isolated         │\n",
        "│  HEAVY_POOL     │ 5        │ Container-based, >1s, resource-isolated  │\n",
        "│  GPU_POOL       │ 2        │ GPU-enabled, ML inference, matrix ops    │\n",
        "│  MEMORY_POOL    │ 3        │ High-RAM, >4GB tasks, data processing    │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: AdaptiveResourceAllocator\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "BACKGROUND PROCESS: Continuously adjusts pool sizes based on demand\n",
        "\n",
        "STATE:\n",
        "    pool_sizes: Map<PoolType, Integer>\n",
        "    queue_depths: Map<PoolType, Integer>\n",
        "    utilization: Map<PoolType, Float>\n",
        "    historical_demand: TimeSeries<Map<PoolType, Integer>>\n",
        "\n",
        "PROCEDURE:\n",
        "    LOOP every ALLOCATION_INTERVAL:\n",
        "        \n",
        "        1. MEASURE CURRENT STATE\n",
        "           FOR EACH pool_type IN PoolTypes:\n",
        "               queue_depths[pool_type] ← GetQueueDepth(pool_type)\n",
        "               utilization[pool_type] ← GetPoolUtilization(pool_type)\n",
        "        \n",
        "        2. PREDICT NEAR-TERM DEMAND\n",
        "           FOR EACH pool_type IN PoolTypes:\n",
        "               // Analyze pending tasks in graph\n",
        "               pending_demand ← CountPendingTasksOfType(pool_type)\n",
        "               \n",
        "               // Time-series prediction for bursty workloads\n",
        "               predicted_burst ← PredictDemandSpike(historical_demand[pool_type])\n",
        "               \n",
        "               target_capacity[pool_type] ← MAX(\n",
        "                   current_demand: queue_depths[pool_type] + pending_demand,\n",
        "                   predicted_demand: predicted_burst,\n",
        "                   minimum: MIN_POOL_SIZE[pool_type]\n",
        "               )\n",
        "        \n",
        "        3. COMPUTE SCALING DECISIONS\n",
        "           FOR EACH pool_type IN PoolTypes:\n",
        "               current ← pool_sizes[pool_type]\n",
        "               target ← target_capacity[pool_type]\n",
        "               \n",
        "               IF target > current * SCALE_UP_THRESHOLD:\n",
        "                   // Scale up aggressively\n",
        "                   new_size ← MIN(target * 1.2, MAX_POOL_SIZE[pool_type])\n",
        "                   ScalePool(pool_type, new_size)\n",
        "               \n",
        "               ELIF target < current * SCALE_DOWN_THRESHOLD:\n",
        "                   // Scale down conservatively\n",
        "                   IF utilization[pool_type] < 0.3 FOR last 5 minutes:\n",
        "                       new_size ← MAX(target, MIN_POOL_SIZE[pool_type])\n",
        "                       ScalePool(pool_type, new_size)\n",
        "        \n",
        "        4. REBALANCE ACROSS POOLS\n",
        "           // Move workers between compatible pools if imbalanced\n",
        "           FOR EACH (over_pool, under_pool) IN FindImbalancedPairs():\n",
        "               IF AreCompatible(over_pool, under_pool):\n",
        "                   TransferWorker(over_pool, under_pool)\n",
        "        \n",
        "        5. RECORD METRICS\n",
        "           historical_demand.append(now(), queue_depths)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: AllocateWorker\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  task: TaskNode\n",
        "        priority: Priority (HIGH|NORMAL|LOW)\n",
        "\n",
        "OUTPUT: worker: Worker\n",
        "\n",
        "PROCEDURE:\n",
        "    1. DETERMINE OPTIMAL POOL\n",
        "       candidate_pools ← []\n",
        "       \n",
        "       // Primary selection by task characteristics\n",
        "       IF task.estimated_duration < 1ms:\n",
        "           candidate_pools.append(NANO_POOL)\n",
        "       ELIF task.estimated_duration < 10ms:\n",
        "           candidate_pools.append(MICRO_POOL)\n",
        "       ELIF task.gpu_required:\n",
        "           candidate_pools.append(GPU_POOL)\n",
        "       ELIF task.memory_mb > 4096:\n",
        "           candidate_pools.append(MEMORY_POOL)\n",
        "       ELIF task.estimated_duration > 1s:\n",
        "           candidate_pools.append(HEAVY_POOL)\n",
        "       ELSE:\n",
        "           candidate_pools.append(STANDARD_POOL)\n",
        "       \n",
        "       // Fallback options\n",
        "       candidate_pools.extend(GetFallbackPools(candidate_pools[0]))\n",
        "    \n",
        "    2. SELECT BEST AVAILABLE WORKER\n",
        "       FOR EACH pool_type IN candidate_pools:\n",
        "           pool ← GetPool(pool_type)\n",
        "           \n",
        "           // Check for task affinity (warm cache, loaded libraries)\n",
        "           affinity_worker ← pool.findWorkerWithAffinity(task.type)\n",
        "           IF affinity_worker AND affinity_worker.available:\n",
        "               RETURN affinity_worker\n",
        "           \n",
        "           // Check general availability\n",
        "           available_worker ← pool.getAvailableWorker()\n",
        "           IF available_worker:\n",
        "               RETURN available_worker\n",
        "       \n",
        "       // No workers available - queue or scale\n",
        "       IF priority = HIGH:\n",
        "           // Emergency scale-up\n",
        "           new_worker ← SpawnWorker(candidate_pools[0])\n",
        "           RETURN new_worker\n",
        "       ELSE:\n",
        "           // Wait for availability\n",
        "           RETURN pool.waitForAvailableWorker(timeout: ALLOCATION_TIMEOUT)\n",
        "    \n",
        "    3. HANDLE ALLOCATION FAILURE\n",
        "       IF no worker obtained:\n",
        "           IF task.is_preemptible:\n",
        "               // Preempt lower priority task\n",
        "               victim ← FindPreemptibleTask(candidate_pools[0])\n",
        "               IF victim:\n",
        "                   PreemptTask(victim)\n",
        "                   RETURN victim.worker\n",
        "           \n",
        "           RAISE ResourceExhaustedError(task)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: PredictResourceRequirements\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  task: TaskNode\n",
        "OUTPUT: requirements: ResourceRequirements\n",
        "\n",
        "PROCEDURE:\n",
        "    // Use ML model trained on historical task executions\n",
        "    \n",
        "    1. EXTRACT FEATURES\n",
        "       features ← {\n",
        "           task_type: task.type,\n",
        "           input_size: EstimateInputSize(task.inputs),\n",
        "           historical_avg_cpu: GetHistoricalAvg(task.type, \"cpu\"),\n",
        "           historical_avg_mem: GetHistoricalAvg(task.type, \"memory\"),\n",
        "           historical_p99_duration: GetHistoricalP99(task.type, \"duration\"),\n",
        "           input_complexity: EstimateInputComplexity(task.inputs),\n",
        "           time_of_day: CurrentHour(),  // Capture load patterns\n",
        "           concurrent_tasks: CountConcurrentTasks()\n",
        "       }\n",
        "    \n",
        "    2. PREDICT WITH SAFETY MARGIN\n",
        "       base_prediction ← ResourcePredictor.predict(features)\n",
        "       \n",
        "       // Add safety margins based on variance\n",
        "       variance ← GetHistoricalVariance(task.type)\n",
        "       \n",
        "       requirements ← {\n",
        "           cpu: base_prediction.cpu * (1 + variance.cpu_factor),\n",
        "           memory: base_prediction.memory * (1 + variance.memory_factor),\n",
        "           duration: base_prediction.duration * (1 + variance.duration_factor),\n",
        "           gpu_probability: base_prediction.gpu_probability\n",
        "       }\n",
        "       \n",
        "       // Apply minimum guarantees\n",
        "       requirements.cpu ← MAX(requirements.cpu, MIN_CPU_ALLOCATION)\n",
        "       requirements.memory ← MAX(requirements.memory, MIN_MEMORY_ALLOCATION)\n",
        "    \n",
        "    RETURN requirements\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# FAULT TOLERANCE & SELF-HEALING\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "COMPREHENSIVE FAILURE HANDLING FRAMEWORK\n",
        "=============================================================================\n",
        "\n",
        "FAILURE TAXONOMY:\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│ FAILURE TYPE        │ DETECTION METHOD    │ RECOVERY STRATEGY          │\n",
        "├─────────────────────────────────────────────────────────────────────────┤\n",
        "│ TRANSIENT           │ Exception type      │ Exponential backoff retry  │\n",
        "│ RESOURCE_EXHAUSTED  │ OOM/CPU signals     │ Scale resources + retry    │\n",
        "│ TIMEOUT             │ Deadline exceeded   │ Extend timeout + retry     │\n",
        "│ VALIDATION          │ Input validation    │ Dead-letter, no retry      │\n",
        "│ DEPENDENCY_FAILED   │ Upstream failure    │ Skip or alternative path   │\n",
        "│ WORKER_CRASHED      │ Heartbeat timeout   │ Reassign to new worker     │\n",
        "│ NETWORK_PARTITION   │ Connection timeout  │ Wait + retry with backoff  │\n",
        "│ DATA_CORRUPTION     │ Checksum mismatch   │ Restore from checkpoint    │\n",
        "│ POISON_PILL         │ Repeated failure    │ Quarantine + alert         │\n",
        "└─────────────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: ExponentialBackoffWithJitter\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  attempt: Integer\n",
        "        retry_policy: RetryPolicy\n",
        "\n",
        "OUTPUT: delay: Duration\n",
        "\n",
        "PROCEDURE:\n",
        "    base_delay ← retry_policy.initial_delay\n",
        "    max_delay ← retry_policy.max_delay\n",
        "    \n",
        "    // Exponential component\n",
        "    exponential_delay ← base_delay * (2 ^ attempt)\n",
        "    \n",
        "    // Cap at maximum\n",
        "    capped_delay ← MIN(exponential_delay, max_delay)\n",
        "    \n",
        "    // Add jitter to prevent thundering herd\n",
        "    jitter_range ← capped_delay * retry_policy.jitter_factor\n",
        "    jitter ← random(-jitter_range, +jitter_range)\n",
        "    \n",
        "    final_delay ← capped_delay + jitter\n",
        "    \n",
        "    RETURN MAX(final_delay, base_delay)  // Never below base\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: CheckpointController\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PURPOSE: Enable resumable execution for long-running tasks\n",
        "\n",
        "STATE:\n",
        "    checkpoint_store: DistributedStore (S3/Minio)\n",
        "    checkpoint_interval: Duration\n",
        "    checkpoint_registry: Map<TaskId, List<Checkpoint>>\n",
        "\n",
        "PROCEDURE OnTaskStart(task):\n",
        "    IF task.checkpoint_enabled:\n",
        "        // Register checkpoint hooks\n",
        "        task.registerProgressHook(OnProgress)\n",
        "        \n",
        "        // Check for existing checkpoint\n",
        "        latest_checkpoint ← GetLatestCheckpoint(task.id)\n",
        "        IF latest_checkpoint AND latest_checkpoint.valid:\n",
        "            RETURN RestoreFromCheckpoint(task, latest_checkpoint)\n",
        "    \n",
        "    RETURN null  // Start fresh\n",
        "\n",
        "PROCEDURE OnProgress(task, progress, state):\n",
        "    IF ShouldCheckpoint(task, progress):\n",
        "        checkpoint ← CreateCheckpoint(task, state)\n",
        "        SaveCheckpoint(checkpoint)\n",
        "        PruneOldCheckpoints(task.id)\n",
        "\n",
        "PROCEDURE ShouldCheckpoint(task, progress):\n",
        "    last_checkpoint ← GetLastCheckpointTime(task.id)\n",
        "    time_since_last ← now() - last_checkpoint\n",
        "    \n",
        "    // Checkpoint based on time interval\n",
        "    IF time_since_last > checkpoint_interval:\n",
        "        RETURN true\n",
        "    \n",
        "    // Checkpoint at significant progress milestones\n",
        "    IF progress IN [0.25, 0.50, 0.75]:\n",
        "        RETURN true\n",
        "    \n",
        "    // Checkpoint before risky operations\n",
        "    IF task.next_operation.is_risky:\n",
        "        RETURN true\n",
        "    \n",
        "    RETURN false\n",
        "\n",
        "PROCEDURE CreateCheckpoint(task, state):\n",
        "    checkpoint ← {\n",
        "        id: GenerateCheckpointId(),\n",
        "        task_id: task.id,\n",
        "        timestamp: now(),\n",
        "        progress: task.current_progress,\n",
        "        state: SerializeState(state),\n",
        "        state_hash: ComputeHash(state),\n",
        "        inputs_hash: ComputeHash(task.inputs),\n",
        "        version: CHECKPOINT_VERSION\n",
        "    }\n",
        "    \n",
        "    RETURN checkpoint\n",
        "\n",
        "PROCEDURE RestoreFromCheckpoint(task, checkpoint):\n",
        "    // Validate checkpoint integrity\n",
        "    IF ComputeHash(checkpoint.state) ≠ checkpoint.state_hash:\n",
        "        WARN \"Checkpoint corrupted\"\n",
        "        RETURN null\n",
        "    \n",
        "    // Validate input compatibility\n",
        "    IF ComputeHash(task.inputs) ≠ checkpoint.inputs_hash:\n",
        "        WARN \"Inputs changed since checkpoint\"\n",
        "        RETURN null\n",
        "    \n",
        "    restored_state ← DeserializeState(checkpoint.state)\n",
        "    task.current_progress ← checkpoint.progress\n",
        "    \n",
        "    EmitEvent(CheckpointRestored, task, checkpoint)\n",
        "    \n",
        "    RETURN restored_state\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: DeadLetterQueueHandler\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PURPOSE: Quarantine permanently failed tasks for analysis\n",
        "\n",
        "STATE:\n",
        "    dlq: MessageQueue (Kafka topic: \"tasks.dead-letter\")\n",
        "    quarantine_store: Database\n",
        "    alert_thresholds: Map<TaskType, Integer>\n",
        "    failure_counts: Map<TaskType, Integer>\n",
        "\n",
        "PROCEDURE EnqueueToDeadLetter(task, error, context):\n",
        "    1. CREATE DLQ ENTRY\n",
        "       entry ← {\n",
        "           task_id: task.id,\n",
        "           task_type: task.type,\n",
        "           task_definition: SerializeTaskDefinition(task),\n",
        "           inputs: task.inputs,\n",
        "           error: {\n",
        "               type: error.type,\n",
        "               message: error.message,\n",
        "               stacktrace: error.stacktrace,\n",
        "               timestamp: now()\n",
        "           },\n",
        "           execution_context: {\n",
        "               attempt_count: context.attempts[task],\n",
        "               graph_id: context.graph.id,\n",
        "               worker_id: context.last_worker,\n",
        "               duration: task.actual_duration\n",
        "           },\n",
        "           metadata: {\n",
        "               created_at: now(),\n",
        "               expires_at: now() + DLQ_RETENTION_PERIOD,\n",
        "               reprocessable: task.idempotency_class IN [PURE, IDEMPOTENT]\n",
        "           }\n",
        "       }\n",
        "    \n",
        "    2. PERSIST TO DLQ\n",
        "       dlq.publish(entry)\n",
        "       quarantine_store.insert(entry)\n",
        "    \n",
        "    3. UPDATE FAILURE COUNTS\n",
        "       failure_counts[task.type] ← failure_counts[task.type] + 1\n",
        "       \n",
        "       IF failure_counts[task.type] > alert_thresholds[task.type]:\n",
        "           TriggerAlert(\n",
        "               severity: HIGH,\n",
        "               message: \"Task type exceeds failure threshold\",\n",
        "               task_type: task.type,\n",
        "               count: failure_counts[task.type]\n",
        "           )\n",
        "    \n",
        "    4. PATTERN ANALYSIS\n",
        "       // Background process to detect systemic issues\n",
        "       AnalyzeFailurePatterns(task.type, error.type)\n",
        "\n",
        "PROCEDURE ReprocessFromDeadLetter(entry_id):\n",
        "    entry ← quarantine_store.get(entry_id)\n",
        "    \n",
        "    IF NOT entry.reprocessable:\n",
        "        RAISE CannotReprocessError(\"Non-idempotent task\")\n",
        "    \n",
        "    // Recreate task from stored definition\n",
        "    task ← DeserializeTaskDefinition(entry.task_definition)\n",
        "    task.inputs ← entry.inputs\n",
        "    task.retry_count ← 0  // Reset retry count\n",
        "    \n",
        "    // Mark as reprocessing\n",
        "    quarantine_store.update(entry_id, status: REPROCESSING)\n",
        "    \n",
        "    // Resubmit to queue with context\n",
        "    ready_queue.enqueue(CreateQueueEntry(task), context: \"reprocessed_from_dlq\")\n",
        "    \n",
        "    EmitEvent(TaskReprocessed, task, entry_id)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: CircuitBreaker\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PURPOSE: Prevent cascade failures by isolating failing components\n",
        "\n",
        "STATE per component:\n",
        "    state: CLOSED | OPEN | HALF_OPEN\n",
        "    failure_count: Integer\n",
        "    success_count: Integer\n",
        "    last_failure_time: Timestamp\n",
        "    threshold: Integer\n",
        "    timeout: Duration\n",
        "    half_open_requests: Integer\n",
        "\n",
        "PROCEDURE Execute(component, operation):\n",
        "    circuit ← GetCircuit(component)\n",
        "    \n",
        "    SWITCH circuit.state:\n",
        "        CASE CLOSED:\n",
        "            TRY:\n",
        "                result ← operation()\n",
        "                circuit.failure_count ← 0\n",
        "                RETURN result\n",
        "            CATCH error:\n",
        "                circuit.failure_count ← circuit.failure_count + 1\n",
        "                circuit.last_failure_time ← now()\n",
        "                \n",
        "                IF circuit.failure_count >= circuit.threshold:\n",
        "                    TransitionTo(circuit, OPEN)\n",
        "                \n",
        "                RAISE error\n",
        "        \n",
        "        CASE OPEN:\n",
        "            IF now() - circuit.last_failure_time > circuit.timeout:\n",
        "                TransitionTo(circuit, HALF_OPEN)\n",
        "                // Fall through to HALF_OPEN\n",
        "            ELSE:\n",
        "                RAISE CircuitOpenError(component)\n",
        "        \n",
        "        CASE HALF_OPEN:\n",
        "            IF circuit.half_open_requests >= HALF_OPEN_LIMIT:\n",
        "                RAISE CircuitOpenError(component)\n",
        "            \n",
        "            circuit.half_open_requests ← circuit.half_open_requests + 1\n",
        "            \n",
        "            TRY:\n",
        "                result ← operation()\n",
        "                circuit.success_count ← circuit.success_count + 1\n",
        "                \n",
        "                IF circuit.success_count >= SUCCESS_THRESHOLD:\n",
        "                    TransitionTo(circuit, CLOSED)\n",
        "                \n",
        "                RETURN result\n",
        "            CATCH error:\n",
        "                TransitionTo(circuit, OPEN)\n",
        "                RAISE error\n",
        "\n",
        "PROCEDURE TransitionTo(circuit, new_state):\n",
        "    old_state ← circuit.state\n",
        "    circuit.state ← new_state\n",
        "    \n",
        "    SWITCH new_state:\n",
        "        CASE CLOSED:\n",
        "            circuit.failure_count ← 0\n",
        "            circuit.success_count ← 0\n",
        "        CASE OPEN:\n",
        "            circuit.half_open_requests ← 0\n",
        "        CASE HALF_OPEN:\n",
        "            circuit.success_count ← 0\n",
        "            circuit.half_open_requests ← 0\n",
        "    \n",
        "    EmitEvent(CircuitStateChange, circuit.component, old_state, new_state)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# BACKPRESSURE & FLOW CONTROL\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "ADAPTIVE BACKPRESSURE MECHANISM\n",
        "=============================================================================\n",
        "\n",
        "PROBLEM: Without backpressure, fast producers overwhelm slow consumers,\n",
        "         causing memory exhaustion, increased latency, and cascade failures.\n",
        "\n",
        "SOLUTION: Multi-level backpressure with adaptive flow control\n",
        "\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: BackpressureController\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "STATE:\n",
        "    queue_depths: Map<QueueId, Integer>\n",
        "    processing_rates: Map<QueueId, Float>  // tasks/second\n",
        "    arrival_rates: Map<QueueId, Float>     // tasks/second\n",
        "    pressure_levels: Map<QueueId, PressureLevel>\n",
        "    \n",
        "    PRESSURE_LEVELS: NORMAL | ELEVATED | HIGH | CRITICAL\n",
        "\n",
        "PROCEDURE MonitorAndApply():\n",
        "    LOOP every PRESSURE_CHECK_INTERVAL:\n",
        "        FOR EACH queue_id IN monitored_queues:\n",
        "            depth ← queue_depths[queue_id]\n",
        "            processing_rate ← processing_rates[queue_id]\n",
        "            arrival_rate ← arrival_rates[queue_id]\n",
        "            \n",
        "            // Compute pressure metrics\n",
        "            drain_time ← depth / processing_rate IF processing_rate > 0 ELSE INFINITY\n",
        "            growth_rate ← arrival_rate - processing_rate\n",
        "            \n",
        "            // Determine pressure level\n",
        "            pressure ← CASE:\n",
        "                depth < LOW_THRESHOLD AND growth_rate <= 0:\n",
        "                    NORMAL\n",
        "                depth < MEDIUM_THRESHOLD OR (depth < HIGH_THRESHOLD AND growth_rate <= 0):\n",
        "                    ELEVATED\n",
        "                depth < HIGH_THRESHOLD OR drain_time < CRITICAL_DRAIN_TIME:\n",
        "                    HIGH\n",
        "                ELSE:\n",
        "                    CRITICAL\n",
        "            \n",
        "            IF pressure ≠ pressure_levels[queue_id]:\n",
        "                ApplyBackpressure(queue_id, pressure)\n",
        "                pressure_levels[queue_id] ← pressure\n",
        "\n",
        "PROCEDURE ApplyBackpressure(queue_id, level):\n",
        "    SWITCH level:\n",
        "        CASE NORMAL:\n",
        "            // Full speed\n",
        "            SetIngestionRate(queue_id, UNLIMITED)\n",
        "            SetBatchSize(queue_id, NORMAL_BATCH_SIZE)\n",
        "            EnableSpeculativeExecution(queue_id)\n",
        "        \n",
        "        CASE ELEVATED:\n",
        "            // Slight throttling\n",
        "            SetIngestionRate(queue_id, 0.8 * MAX_RATE)\n",
        "            SetBatchSize(queue_id, NORMAL_BATCH_SIZE)\n",
        "            EnableSpeculativeExecution(queue_id)\n",
        "        \n",
        "        CASE HIGH:\n",
        "            // Significant throttling\n",
        "            SetIngestionRate(queue_id, 0.5 * MAX_RATE)\n",
        "            SetBatchSize(queue_id, SMALL_BATCH_SIZE)\n",
        "            DisableSpeculativeExecution(queue_id)\n",
        "            ScaleUpWorkers(queue_id)\n",
        "        \n",
        "        CASE CRITICAL:\n",
        "            // Emergency measures\n",
        "            SetIngestionRate(queue_id, 0.1 * MAX_RATE)\n",
        "            SetBatchSize(queue_id, MINIMUM_BATCH_SIZE)\n",
        "            DisableSpeculativeExecution(queue_id)\n",
        "            ScaleUpWorkersAggressive(queue_id)\n",
        "            RejectNewGraphs(queue_id)\n",
        "            TriggerAlert(CRITICAL, \"Queue backpressure critical\", queue_id)\n",
        "    \n",
        "    EmitEvent(BackpressureApplied, queue_id, level)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: AdaptiveLoadShedding\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PURPOSE: Gracefully degrade service under extreme load\n",
        "\n",
        "PROCEDURE EvaluateAndShed():\n",
        "    current_load ← ComputeSystemLoad()\n",
        "    capacity ← ComputeSystemCapacity()\n",
        "    \n",
        "    IF current_load > capacity * SHED_THRESHOLD:\n",
        "        overload_factor ← current_load / capacity\n",
        "        \n",
        "        // Determine shed strategy based on overload severity\n",
        "        CASE:\n",
        "            overload_factor < 1.2:\n",
        "                // Shed only BACKGROUND criticality tasks\n",
        "                ShedTasks(criticality: BACKGROUND)\n",
        "            \n",
        "            overload_factor < 1.5:\n",
        "                // Shed BACKGROUND and LOW criticality\n",
        "                ShedTasks(criticality: [BACKGROUND, LOW])\n",
        "            \n",
        "            overload_factor < 2.0:\n",
        "                // Shed up to MEDIUM, keep CRITICAL and HIGH\n",
        "                ShedTasks(criticality: [BACKGROUND, LOW, MEDIUM])\n",
        "            \n",
        "            ELSE:\n",
        "                // Extreme overload - shed all but CRITICAL\n",
        "                ShedTasks(criticality: [BACKGROUND, LOW, MEDIUM, HIGH])\n",
        "                TriggerAlert(CRITICAL, \"Extreme load shedding active\")\n",
        "\n",
        "PROCEDURE ShedTasks(criticality_levels):\n",
        "    FOR EACH task IN GetPendingTasks():\n",
        "        IF task.criticality IN criticality_levels:\n",
        "            // Don't shed if already running\n",
        "            IF task.state = PENDING OR task.state = READY:\n",
        "                task.state ← SHED\n",
        "                NotifyGraph(task.graph_id, TaskShed, task)\n",
        "                EmitEvent(TaskShed, task, \"load_shedding\")\n",
        "                \n",
        "                // Schedule for later if recoverable\n",
        "                IF task.shed_policy = DEFER:\n",
        "                    DeferredQueue.enqueue(task, delay: SHED_DEFER_DELAY)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "ALGORITHM: TokenBucketRateLimiter\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PURPOSE: Smooth bursty traffic while allowing short bursts\n",
        "\n",
        "STATE per limiter:\n",
        "    tokens: Float\n",
        "    capacity: Float\n",
        "    refill_rate: Float  // tokens per second\n",
        "    last_refill: Timestamp\n",
        "\n",
        "PROCEDURE Acquire(limiter, requested_tokens):\n",
        "    RefillTokens(limiter)\n",
        "    \n",
        "    IF limiter.tokens >= requested_tokens:\n",
        "        limiter.tokens ← limiter.tokens - requested_tokens\n",
        "        RETURN ACQUIRED\n",
        "    \n",
        "    ELIF limiter.allow_partial:\n",
        "        available ← limiter.tokens\n",
        "        limiter.tokens ← 0\n",
        "        RETURN PARTIAL(available)\n",
        "    \n",
        "    ELSE:\n",
        "        wait_time ← (requested_tokens - limiter.tokens) / limiter.refill_rate\n",
        "        RETURN WAIT(wait_time)\n",
        "\n",
        "PROCEDURE RefillTokens(limiter):\n",
        "    now_ts ← now()\n",
        "    elapsed ← now_ts - limiter.last_refill\n",
        "    \n",
        "    refill_amount ← elapsed.seconds * limiter.refill_rate\n",
        "    limiter.tokens ← MIN(limiter.tokens + refill_amount, limiter.capacity)\n",
        "    limiter.last_refill ← now_ts\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# OBSERVABILITY & METRICS\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "COMPREHENSIVE OBSERVABILITY FRAMEWORK\n",
        "=============================================================================\n",
        "\n",
        "THREE PILLARS:\n",
        "1. METRICS - Aggregated numerical measurements\n",
        "2. LOGS - Structured event records\n",
        "3. TRACES - Distributed request flows\n",
        "\n",
        "=============================================================================\n",
        "\n",
        "METRICS SPECIFICATION\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "COUNTER METRICS (monotonically increasing):\n",
        "    adage_tasks_total{status, task_type, graph_id}\n",
        "    adage_tasks_retried_total{task_type, error_type}\n",
        "    adage_speculative_executions_total{outcome}  // validated|rolled_back\n",
        "    adage_checkpoints_created_total{task_type}\n",
        "    adage_dead_letters_total{task_type, error_type}\n",
        "\n",
        "GAUGE METRICS (current values):\n",
        "    adage_queue_depth{queue_name, priority}\n",
        "    adage_active_tasks{state, pool_type}\n",
        "    adage_worker_pool_size{pool_type}\n",
        "    adage_worker_utilization{pool_type}\n",
        "    adage_memory_usage_bytes{component}\n",
        "    adage_circuit_breaker_state{component}  // 0=closed, 1=open, 2=half_open\n",
        "\n",
        "HISTOGRAM METRICS (distributions):\n",
        "    adage_task_duration_seconds{task_type, status}\n",
        "    adage_queue_wait_time_seconds{queue_name}\n",
        "    adage_speculation_lead_time_seconds{task_type}\n",
        "    adage_checkpoint_size_bytes{task_type}\n",
        "    adage_graph_completion_time_seconds{graph_type}\n",
        "\n",
        "SUMMARY METRICS (percentiles):\n",
        "    adage_task_latency_summary{task_type, quantile}\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "STRUCTURED LOGGING SCHEMA\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "LogEvent {\n",
        "    timestamp:      ISO8601\n",
        "    level:          TRACE|DEBUG|INFO|WARN|ERROR|FATAL\n",
        "    event_type:     EventType enum\n",
        "    \n",
        "    // Context\n",
        "    trace_id:       UUID\n",
        "    span_id:        UUID\n",
        "    graph_id:       UUID\n",
        "    task_id:        UUID (optional)\n",
        "    worker_id:      String (optional)\n",
        "    \n",
        "    // Event details\n",
        "    message:        String\n",
        "    attributes:     Map<String, Any>\n",
        "    \n",
        "    // Error context (if applicable)\n",
        "    error: {\n",
        "        type:       String\n",
        "        message:    String\n",
        "        stacktrace: String\n",
        "        cause:      Error (nested)\n",
        "    }\n",
        "}\n",
        "\n",
        "EVENT TYPES:\n",
        "    // Graph lifecycle\n",
        "    GRAPH_SUBMITTED, GRAPH_COMPILED, GRAPH_STARTED\n",
        "    GRAPH_COMPLETED, GRAPH_FAILED, GRAPH_CANCELLED\n",
        "    \n",
        "    // Task lifecycle\n",
        "    TASK_READY, TASK_DISPATCHED, TASK_STARTED\n",
        "    TASK_COMPLETED, TASK_FAILED, TASK_RETRIED\n",
        "    TASK_CHECKPOINTED, TASK_RESTORED\n",
        "    TASK_SPECULATION_STARTED, TASK_SPECULATION_VALIDATED\n",
        "    TASK_SPECULATION_ROLLED_BACK, TASK_DEAD_LETTERED\n",
        "    \n",
        "    // System events\n",
        "    WORKER_STARTED, WORKER_STOPPED, WORKER_HEALTH_CHECK\n",
        "    POOL_SCALED, CIRCUIT_STATE_CHANGE\n",
        "    BACKPRESSURE_APPLIED, LOAD_SHED_ACTIVATED\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "DISTRIBUTED TRACING\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "Trace Structure:\n",
        "    \n",
        "    GraphExecution (root span)\n",
        "    ├── Compilation\n",
        "    │   ├── GraphValidation\n",
        "    │   ├── TopologicalSort\n",
        "    │   ├── CriticalPathAnalysis\n",
        "    │   └── OptimizationPass\n",
        "    │\n",
        "    ├── Stage[0] (parallel span group)\n",
        "    │   ├── Task[T1] (span)\n",
        "    │   │   ├── Dispatch\n",
        "    │   │   ├── Execution\n",
        "    │   │   └── ResultStore\n",
        "    │   └── Task[T2] (span)\n",
        "    │       ├── Dispatch\n",
        "    │       ├── Execution\n",
        "    │       └── ResultStore\n",
        "    │\n",
        "    ├── Stage[1]\n",
        "    │   ├── Task[T3]\n",
        "    │   │   ├── Dispatch\n",
        "    │   │   ├── Speculation (child span if speculative)\n",
        "    │   │   ├── Execution\n",
        "    │   │   └── ResultStore\n",
        "    │   └── Task[T4]\n",
        "    │\n",
        "    └── Finalization\n",
        "        ├── ResultAggregation\n",
        "        └── Cleanup\n",
        "\n",
        "Span Attributes:\n",
        "    task.name, task.type, task.criticality\n",
        "    worker.id, worker.pool_type\n",
        "    execution.attempt, execution.duration_ms\n",
        "    speculation.enabled, speculation.outcome\n",
        "    checkpoint.count, checkpoint.total_size\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "HEALTH CHECK ENDPOINTS\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "/health/live\n",
        "    Purpose: Kubernetes liveness probe\n",
        "    Response: 200 if process running\n",
        "    \n",
        "/health/ready\n",
        "    Purpose: Kubernetes readiness probe\n",
        "    Response: 200 if accepting work, 503 otherwise\n",
        "    Checks: Queue connectivity, worker pool health, storage availability\n",
        "    \n",
        "/health/detailed\n",
        "    Purpose: Detailed system status\n",
        "    Response: JSON with component-level health\n",
        "    {\n",
        "        status: \"healthy\" | \"degraded\" | \"unhealthy\",\n",
        "        components: {\n",
        "            scheduler: { status, latency_ms, queue_depth },\n",
        "            workers: { status, pool_sizes, utilization },\n",
        "            storage: { status, latency_ms },\n",
        "            messaging: { status, lag }\n",
        "        },\n",
        "        checks_passed: 8,\n",
        "        checks_total: 10\n",
        "    }\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "-->\n",
        "\n",
        "---\n",
        "\n",
        "# PSEUDO ALGORITHM SPECIFICATIONS\n",
        "\n",
        "<!--\n",
        "=============================================================================\n",
        "COMPLETE SYSTEM INITIALIZATION\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: SystemBootstrap\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "PROCEDURE:\n",
        "    1. LOAD CONFIGURATION\n",
        "       config ← LoadConfig(environment: ENV)\n",
        "       ValidateConfig(config)\n",
        "    \n",
        "    2. INITIALIZE PERSISTENCE\n",
        "       state_store ← InitializeRedis(config.redis)\n",
        "       result_cache ← InitializeRedis(config.redis_cache)\n",
        "       checkpoint_store ← InitializeS3(config.s3)\n",
        "       dlq ← InitializeKafka(config.kafka, topic: \"dead-letter\")\n",
        "    \n",
        "    3. INITIALIZE WORKER POOLS\n",
        "       FOR EACH pool_config IN config.worker_pools:\n",
        "           pool ← CreateWorkerPool(pool_config)\n",
        "           RegisterPool(pool)\n",
        "           StartHealthMonitor(pool)\n",
        "    \n",
        "    4. INITIALIZE SCHEDULERS\n",
        "       compilation_scheduler ← StartCompilationScheduler(config)\n",
        "       execution_scheduler ← StartExecutionScheduler(config)\n",
        "       speculation_controller ← StartSpeculationController(config)\n",
        "    \n",
        "    5. INITIALIZE OBSERVABILITY\n",
        "       metrics_exporter ← StartPrometheusExporter(config.metrics_port)\n",
        "       trace_exporter ← StartJaegerExporter(config.jaeger_endpoint)\n",
        "       log_shipper ← StartFluentBit(config.log_endpoint)\n",
        "    \n",
        "    6. INITIALIZE CONTROLLERS\n",
        "       backpressure_controller ← StartBackpressureController(config)\n",
        "       resource_allocator ← StartResourceAllocator(config)\n",
        "       circuit_breaker_manager ← StartCircuitBreakerManager(config)\n",
        "    \n",
        "    7. START API SERVER\n",
        "       api ← StartAPIServer(config.api_port)\n",
        "       RegisterEndpoints(api, handlers)\n",
        "    \n",
        "    8. SIGNAL READY\n",
        "       MarkSystemReady()\n",
        "       EmitEvent(SystemStarted, config.instance_id)\n",
        "\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "\n",
        "=============================================================================\n",
        "END-TO-END EXECUTION FLOW\n",
        "=============================================================================\n",
        "\n",
        "ALGORITHM: CompleteExecutionPipeline\n",
        "────────────────────────────────────────────────────────────────────────────\n",
        "INPUT:  graph_definition: GraphDefinition\n",
        "        input_data: Map<String, Any>\n",
        "        options: ExecutionOptions\n",
        "\n",
        "OUTPUT: result: ExecutionResult\n",
        "\n",
        "PROCEDURE:\n",
        "    \n",
        "    // PHASE 1: ADMISSION\n",
        "    1.1 VALIDATE INPUT\n",
        "        ValidateGraphDefinition(graph_definition)\n",
        "        ValidateInputData(input_data, graph_definition.input_schema)\n",
        "    \n",
        "    1.2 CHECK CAPACITY\n",
        "        IF BackpressureLevel() = CRITICAL:\n",
        "            IF NOT options.bypass_backpressure:\n",
        "                RAISE SystemOverloadedError()\n",
        "    \n",
        "    1.3 CREATE EXECUTION CONTEXT\n",
        "        execution_id ← GenerateExecutionId()\n",
        "        context ← CreateExecutionContext(execution_id, options)\n",
        "    \n",
        "    // PHASE 2: COMPILATION\n",
        "    2.1 BUILD GRAPH\n",
        "        graph ← BuildExecutionGraph(graph_definition)\n",
        "    \n",
        "    2.2 VALIDATE GRAPH\n",
        "        ValidateDependencies(graph)\n",
        "        DetectCycles(graph)\n",
        "        ValidateTypes(graph)\n",
        "    \n",
        "    2.3 OPTIMIZE GRAPH\n",
        "        ComputeTopologicalOrder(graph)\n",
        "        ComputeCriticalPath(graph)\n",
        "        FuseCompatibleTasks(graph)\n",
        "        IdentifySpeculativeTasks(graph)\n",
        "    \n",
        "    2.4 GENERATE SCHEDULE\n",
        "        schedule ← GenerateExecutionSchedule(graph)\n",
        "        AllocateResourceEstimates(schedule)\n",
        "    \n",
        "    // PHASE 3: EXECUTION\n",
        "    3.1 INITIALIZE STATE\n",
        "        InitializeTaskStates(context, graph)\n",
        "        StoreInputData(context, input_data)\n",
        "    \n",
        "    3.2 SEED READY TASKS\n",
        "        ready_tasks ← GetTasksWithNoPredecsors(graph)\n",
        "        FOR EACH task IN ready_tasks:\n",
        "            EnqueueTask(task, context)\n",
        "    \n",
        "    3.3 EXECUTE UNTIL COMPLETE\n",
        "        WHILE NOT"
      ],
      "metadata": {
        "id": "0u6bWAv7BoMq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea4GIzGuBjDy"
      },
      "outputs": [],
      "source": []
    }
  ]
}